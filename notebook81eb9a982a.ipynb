{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9996344,"sourceType":"datasetVersion","datasetId":6152552},{"sourceId":9998440,"sourceType":"datasetVersion","datasetId":6154021},{"sourceId":9998909,"sourceType":"datasetVersion","datasetId":6154354},{"sourceId":10036765,"sourceType":"datasetVersion","datasetId":6182187},{"sourceId":10039020,"sourceType":"datasetVersion","datasetId":6183940},{"sourceId":10039383,"sourceType":"datasetVersion","datasetId":6184220},{"sourceId":179012,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":152495,"modelId":174950}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/openai/clip\n!pip install ftfy\n!pip install regex\n!pip install tqdm\n!pip install pillow\n!pip install pytorch\n!pip install torchvision\n!pip install opencv-contrib-python\n!pip install einops\n!pip install grad-cam","metadata":{"trusted":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-11-28T11:55:05.797840Z","iopub.execute_input":"2024-11-28T11:55:05.798286Z","iopub.status.idle":"2024-11-28T11:56:36.223033Z","shell.execute_reply.started":"2024-11-28T11:55:05.798255Z","shell.execute_reply":"2024-11-28T11:56:36.222021Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/clip\n  Cloning https://github.com/openai/clip to /tmp/pip-req-build-hwzj9zu_\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/clip /tmp/pip-req-build-hwzj9zu_\n  Resolved https://github.com/openai/clip to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=583f13c77da2191b9db5b8f124ff81d0cf27102721c76cec0c1693a5300e2f17\n  Stored in directory: /tmp/pip-ephem-wheel-cache-05svqc5h/wheels/1f/79/1c/1fd0db79e903aa56e8aff0effc18abcca5e65dfd9230417259\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.3.1\nRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (6.3.1)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nCollecting pytorch\n  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pytorch\n  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-k06njpkv/pytorch_3864b7d338454777b07ce50c49fe2c07/setup.py\", line 15, in <module>\n  \u001b[31m   \u001b[0m     raise Exception(message)\n  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\nFailed to build pytorch\n\u001b[31mERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.4.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-contrib-python) (1.26.4)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\nCollecting grad-cam\n  Downloading grad-cam-1.5.4.tar.gz (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from grad-cam) (10.3.0)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (2.4.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (0.19.0)\nCollecting ttach (from grad-cam)\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.66.4)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.10.0.84)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from grad-cam) (3.7.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\nDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nBuilding wheels for collected packages: grad-cam\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.4-py3-none-any.whl size=39588 sha256=0d5231865c49699c7ae3d6ffc39c327c986366faeba64271411f65a3c058e099\n  Stored in directory: /root/.cache/pip/wheels/50/b0/82/1f97b5348c7fe9f0ce0ba18497202cafa5dec4562bd5292680\nSuccessfully built grad-cam\nInstalling collected packages: ttach, grad-cam\nSuccessfully installed grad-cam-1.5.4 ttach-0.0.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# AuraSR: GAN-based Super-Resolution for real-world, a reproduction of the GigaGAN* paper. Implementation is\n# based on the unofficial lucidrains/gigagan-pytorch repository. Heavily modified from there.\n#\n# https://mingukkang.github.io/GigaGAN/\nfrom math import log2, ceil\nfrom functools import partial\nfrom typing import Any, Optional, List, Iterable\n\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\nfrom torch import nn, einsum, Tensor\nimport torch.nn.functional as F\n\nfrom einops import rearrange, repeat, reduce\nfrom einops.layers.torch import Rearrange\nfrom torchvision.utils import save_image\nimport math\n\n\ndef get_same_padding(size, kernel, dilation, stride):\n    return ((size - 1) * (stride - 1) + dilation * (kernel - 1)) // 2\n\n\nclass AdaptiveConv2DMod(nn.Module):\n    def __init__(\n        self,\n        dim,\n        dim_out,\n        kernel,\n        *,\n        demod=True,\n        stride=1,\n        dilation=1,\n        eps=1e-8,\n        num_conv_kernels=1,  # set this to be greater than 1 for adaptive\n    ):\n        super().__init__()\n        self.eps = eps\n\n        self.dim_out = dim_out\n\n        self.kernel = kernel\n        self.stride = stride\n        self.dilation = dilation\n        self.adaptive = num_conv_kernels > 1\n\n        self.weights = nn.Parameter(\n            torch.randn((num_conv_kernels, dim_out, dim, kernel, kernel))\n        )\n\n        self.demod = demod\n\n        nn.init.kaiming_normal_(\n            self.weights, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\"\n        )\n\n    def forward(\n        self, fmap, mod: Optional[Tensor] = None, kernel_mod: Optional[Tensor] = None\n    ):\n        \"\"\"\n        notation\n\n        b - batch\n        n - convs\n        o - output\n        i - input\n        k - kernel\n        \"\"\"\n\n        b, h = fmap.shape[0], fmap.shape[-2]\n\n        # account for feature map that has been expanded by the scale in the first dimension\n        # due to multiscale inputs and outputs\n\n        if mod.shape[0] != b:\n            mod = repeat(mod, \"b ... -> (s b) ...\", s=b // mod.shape[0])\n\n        if exists(kernel_mod):\n            kernel_mod_has_el = kernel_mod.numel() > 0\n\n            assert self.adaptive or not kernel_mod_has_el\n\n            if kernel_mod_has_el and kernel_mod.shape[0] != b:\n                kernel_mod = repeat(\n                    kernel_mod, \"b ... -> (s b) ...\", s=b // kernel_mod.shape[0]\n                )\n\n        # prepare weights for modulation\n\n        weights = self.weights\n\n        if self.adaptive:\n            weights = repeat(weights, \"... -> b ...\", b=b)\n\n            # determine an adaptive weight and 'select' the kernel to use with softmax\n\n            assert exists(kernel_mod) and kernel_mod.numel() > 0\n\n            kernel_attn = kernel_mod.softmax(dim=-1)\n            kernel_attn = rearrange(kernel_attn, \"b n -> b n 1 1 1 1\")\n\n            weights = reduce(weights * kernel_attn, \"b n ... -> b ...\", \"sum\")\n\n        # do the modulation, demodulation, as done in stylegan2\n\n        mod = rearrange(mod, \"b i -> b 1 i 1 1\")\n\n        weights = weights * (mod + 1)\n\n        if self.demod:\n            inv_norm = (\n                reduce(weights**2, \"b o i k1 k2 -> b o 1 1 1\", \"sum\")\n                .clamp(min=self.eps)\n                .rsqrt()\n            )\n            weights = weights * inv_norm\n\n        fmap = rearrange(fmap, \"b c h w -> 1 (b c) h w\")\n\n        weights = rearrange(weights, \"b o ... -> (b o) ...\")\n\n        padding = get_same_padding(h, self.kernel, self.dilation, self.stride)\n        fmap = F.conv2d(fmap, weights, padding=padding, groups=b)\n\n        return rearrange(fmap, \"1 (b o) ... -> b o ...\", b=b)\n\n\nclass Attend(nn.Module):\n    def __init__(self, dropout=0.0, flash=False):\n        super().__init__()\n        self.dropout = dropout\n        self.attn_dropout = nn.Dropout(dropout)\n        self.scale = nn.Parameter(torch.randn(1))\n        self.flash = flash\n\n    def flash_attn(self, q, k, v):\n        q, k, v = map(lambda t: t.contiguous(), (q, k, v))\n        out = F.scaled_dot_product_attention(\n            q, k, v, dropout_p=self.dropout if self.training else 0.0\n        )\n        return out\n\n    def forward(self, q, k, v):\n        if self.flash:\n            return self.flash_attn(q, k, v)\n\n        scale = q.shape[-1] ** -0.5\n\n        # similarity\n        sim = einsum(\"b h i d, b h j d -> b h i j\", q, k) * scale\n\n        # attention\n        attn = sim.softmax(dim=-1)\n        attn = self.attn_dropout(attn)\n\n        # aggregate values\n        out = einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n\n        return out\n\n\ndef exists(x):\n    return x is not None\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if callable(d) else d\n\n\ndef cast_tuple(t, length=1):\n    if isinstance(t, tuple):\n        return t\n    return (t,) * length\n\n\ndef identity(t, *args, **kwargs):\n    return t\n\n\ndef is_power_of_two(n):\n    return log2(n).is_integer()\n\n\ndef null_iterator():\n    while True:\n        yield None\n\ndef Downsample(dim, dim_out=None):\n    return nn.Sequential(\n        Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2),\n        nn.Conv2d(dim * 4, default(dim_out, dim), 1),\n    )\n\n\nclass RMSNorm(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n        self.eps = 1e-4\n\n    def forward(self, x):\n        return F.normalize(x, dim=1) * self.g * (x.shape[1] ** 0.5)\n\n\n# building block modules\n\n\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, groups=8, num_conv_kernels=0):\n        super().__init__()\n        self.proj = AdaptiveConv2DMod(\n            dim, dim_out, kernel=3, num_conv_kernels=num_conv_kernels\n        )\n        self.kernel = 3\n        self.dilation = 1\n        self.stride = 1\n\n        self.act = nn.SiLU()\n\n    def forward(self, x, conv_mods_iter: Optional[Iterable] = None):\n        conv_mods_iter = conv_mods_iter\n\n        x = self.proj(x, mod=next(conv_mods_iter), kernel_mod=next(conv_mods_iter))\n\n        x = self.act(x)\n        return x\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(\n        self, dim, dim_out, *, groups=8, num_conv_kernels=0, style_dims: List = []\n    ):\n        super().__init__()\n        style_dims.extend([dim, num_conv_kernels, dim_out, num_conv_kernels])\n\n        self.block1 = Block(\n            dim, dim_out, groups=groups, num_conv_kernels=num_conv_kernels\n        )\n        self.block2 = Block(\n            dim_out, dim_out, groups=groups, num_conv_kernels=num_conv_kernels\n        )\n        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, conv_mods_iter: Optional[Iterable] = None):\n        h = self.block1(x, conv_mods_iter=conv_mods_iter)\n        h = self.block2(h, conv_mods_iter=conv_mods_iter)\n\n        return h + self.res_conv(x)\n\n\nclass LinearAttention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n\n        self.norm = RMSNorm(dim)\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n\n        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1), RMSNorm(dim))\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n\n        x = self.norm(x)\n\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n        )\n\n        q = q.softmax(dim=-2)\n        k = k.softmax(dim=-1)\n\n        q = q * self.scale\n\n        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n\n        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n        return self.to_out(out)\n\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32, flash=False):\n        super().__init__()\n        self.heads = heads\n        hidden_dim = dim_head * heads\n\n        self.norm = RMSNorm(dim)\n\n        self.attend = Attend(flash=flash)\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        x = self.norm(x)\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x y -> b h (x y) c\", h=self.heads), qkv\n        )\n\n        out = self.attend(q, k, v)\n        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n\n        return self.to_out(out)\n\n\n# feedforward\ndef FeedForward(dim, mult=4):\n    return nn.Sequential(\n        RMSNorm(dim),\n        nn.Conv2d(dim, dim * mult, 1),\n        nn.GELU(),\n        nn.Conv2d(dim * mult, dim, 1),\n    )\n\n\n# transformers\nclass Transformer(nn.Module):\n    def __init__(self, dim, dim_head=64, heads=8, depth=1, flash_attn=True, ff_mult=4):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n\n        for _ in range(depth):\n            self.layers.append(\n                nn.ModuleList(\n                    [\n                        Attention(\n                            dim=dim, dim_head=dim_head, heads=heads, flash=flash_attn\n                        ),\n                        FeedForward(dim=dim, mult=ff_mult),\n                    ]\n                )\n            )\n\n    def forward(self, x):\n        for attn, ff in self.layers:\n            x = attn(x) + x\n            x = ff(x) + x\n\n        return x\n\n\nclass LinearTransformer(nn.Module):\n    def __init__(self, dim, dim_head=64, heads=8, depth=1, ff_mult=4):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n\n        for _ in range(depth):\n            self.layers.append(\n                nn.ModuleList(\n                    [\n                        LinearAttention(dim=dim, dim_head=dim_head, heads=heads),\n                        FeedForward(dim=dim, mult=ff_mult),\n                    ]\n                )\n            )\n\n    def forward(self, x):\n        for attn, ff in self.layers:\n            x = attn(x) + x\n            x = ff(x) + x\n\n        return x\n\n\nclass NearestNeighborhoodUpsample(nn.Module):\n    def __init__(self, dim, dim_out=None):\n        super().__init__()\n        dim_out = default(dim_out, dim)\n        self.conv = nn.Conv2d(dim, dim_out, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x):\n\n        if x.shape[0] >= 64:\n            x = x.contiguous()\n\n        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n        x = self.conv(x)\n\n        return x\n\nclass EqualLinear(nn.Module):\n    def __init__(self, dim, dim_out, lr_mul=1, bias=True):\n        super().__init__()\n        self.weight = nn.Parameter(torch.randn(dim_out, dim))\n        if bias:\n            self.bias = nn.Parameter(torch.zeros(dim_out))\n\n        self.lr_mul = lr_mul\n\n    def forward(self, input):\n        return F.linear(input, self.weight * self.lr_mul, bias=self.bias * self.lr_mul)\n\n\nclass StyleGanNetwork(nn.Module):\n    def __init__(self, dim_in=128, dim_out=512, depth=8, lr_mul=0.1, dim_text_latent=0):\n        super().__init__()\n        self.dim_in = dim_in\n        self.dim_out = dim_out\n        self.dim_text_latent = dim_text_latent\n\n        layers = []\n        for i in range(depth):\n            is_first = i == 0\n\n            if is_first:\n                dim_in_layer = dim_in + dim_text_latent\n            else:\n                dim_in_layer = dim_out\n\n            dim_out_layer = dim_out\n\n            layers.extend(\n                [EqualLinear(dim_in_layer, dim_out_layer, lr_mul), nn.LeakyReLU(0.2)]\n            )\n\n        self.net = nn.Sequential(*layers)\n\n    def forward(self, x, text_latent=None):\n        x = F.normalize(x, dim=1)\n        if self.dim_text_latent > 0:\n            assert exists(text_latent)\n            x = torch.cat((x, text_latent), dim=-1)\n        return self.net(x)\n\n\nclass UnetUpsampler(torch.nn.Module):\n\n    def __init__(\n        self,\n        dim: int,\n        *,\n        image_size: int,\n        input_image_size: int,\n        init_dim: Optional[int] = None,\n        out_dim: Optional[int] = None,\n        style_network: Optional[dict] = None,\n        up_dim_mults: tuple = (1, 2, 4, 8, 16),\n        down_dim_mults: tuple = (4, 8, 16),\n        channels: int = 3,\n        resnet_block_groups: int = 8,\n        full_attn: tuple = (False, False, False, True, True),\n        flash_attn: bool = True,\n        self_attn_dim_head: int = 64,\n        self_attn_heads: int = 8,\n        attn_depths: tuple = (2, 2, 2, 2, 4),\n        mid_attn_depth: int = 4,\n        num_conv_kernels: int = 4,\n        resize_mode: str = \"bilinear\",\n        unconditional: bool = True,\n        skip_connect_scale: Optional[float] = None,\n    ):\n        super().__init__()\n        self.style_network = style_network = StyleGanNetwork(**style_network)\n        self.unconditional = unconditional\n        assert not (\n            unconditional\n            and exists(style_network)\n            and style_network.dim_text_latent > 0\n        )\n\n        assert is_power_of_two(image_size) and is_power_of_two(\n            input_image_size\n        ), \"both output image size and input image size must be power of 2\"\n        assert (\n            input_image_size < image_size\n        ), \"input image size must be smaller than the output image size, thus upsampling\"\n\n        self.image_size = image_size\n        self.input_image_size = input_image_size\n\n        style_embed_split_dims = []\n\n        self.channels = channels\n        input_channels = channels\n\n        init_dim = default(init_dim, dim)\n\n        up_dims = [init_dim, *map(lambda m: dim * m, up_dim_mults)]\n        init_down_dim = up_dims[len(up_dim_mults) - len(down_dim_mults)]\n        down_dims = [init_down_dim, *map(lambda m: dim * m, down_dim_mults)]\n        self.init_conv = nn.Conv2d(input_channels, init_down_dim, 7, padding=3)\n\n        up_in_out = list(zip(up_dims[:-1], up_dims[1:]))\n        down_in_out = list(zip(down_dims[:-1], down_dims[1:]))\n\n        block_klass = partial(\n            ResnetBlock,\n            groups=resnet_block_groups,\n            num_conv_kernels=num_conv_kernels,\n            style_dims=style_embed_split_dims,\n        )\n\n        FullAttention = partial(Transformer, flash_attn=flash_attn)\n        *_, mid_dim = up_dims\n\n        self.skip_connect_scale = default(skip_connect_scale, 2**-0.5)\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n\n        block_count = 6\n\n        for ind, (\n            (dim_in, dim_out),\n            layer_full_attn,\n            layer_attn_depth,\n        ) in enumerate(zip(down_in_out, full_attn, attn_depths)):\n            attn_klass = FullAttention if layer_full_attn else LinearTransformer\n\n            blocks = []\n            for i in range(block_count):\n                blocks.append(block_klass(dim_in, dim_in))\n\n            self.downs.append(\n                nn.ModuleList(\n                    [\n                        nn.ModuleList(blocks),\n                        nn.ModuleList(\n                            [\n                                (\n                                    attn_klass(\n                                        dim_in,\n                                        dim_head=self_attn_dim_head,\n                                        heads=self_attn_heads,\n                                        depth=layer_attn_depth,\n                                    )\n                                    if layer_full_attn\n                                    else None\n                                ),\n                                nn.Conv2d(\n                                    dim_in, dim_out, kernel_size=3, stride=2, padding=1\n                                ),\n                            ]\n                        ),\n                    ]\n                )\n            )\n\n        self.mid_block1 = block_klass(mid_dim, mid_dim)\n        self.mid_attn = FullAttention(\n            mid_dim,\n            dim_head=self_attn_dim_head,\n            heads=self_attn_heads,\n            depth=mid_attn_depth,\n        )\n        self.mid_block2 = block_klass(mid_dim, mid_dim)\n\n        *_, last_dim = up_dims\n\n        for ind, (\n            (dim_in, dim_out),\n            layer_full_attn,\n            layer_attn_depth,\n        ) in enumerate(\n            zip(\n                reversed(up_in_out),\n                reversed(full_attn),\n                reversed(attn_depths),\n            )\n        ):\n            attn_klass = FullAttention if layer_full_attn else LinearTransformer\n\n            blocks = []\n            input_dim = dim_in * 2 if ind < len(down_in_out) else dim_in\n            for i in range(block_count):\n                blocks.append(block_klass(input_dim, dim_in))\n\n            self.ups.append(\n                nn.ModuleList(\n                    [\n                        nn.ModuleList(blocks),\n                        nn.ModuleList(\n                            [\n                                NearestNeighborhoodUpsample(\n                                    last_dim if ind == 0 else dim_out,\n                                    dim_in,\n                                ),\n                                (\n                                    attn_klass(\n                                        dim_in,\n                                        dim_head=self_attn_dim_head,\n                                        heads=self_attn_heads,\n                                        depth=layer_attn_depth,\n                                    )\n                                    if layer_full_attn\n                                    else None\n                                ),\n                            ]\n                        ),\n                    ]\n                )\n            )\n\n        self.out_dim = default(out_dim, channels)\n        self.final_res_block = block_klass(dim, dim)\n        self.final_to_rgb = nn.Conv2d(dim, channels, 1)\n        self.resize_mode = resize_mode\n        self.style_to_conv_modulations = nn.Linear(\n            style_network.dim_out, sum(style_embed_split_dims)\n        )\n        self.style_embed_split_dims = style_embed_split_dims\n\n    @property\n    def allowable_rgb_resolutions(self):\n        input_res_base = int(log2(self.input_image_size))\n        output_res_base = int(log2(self.image_size))\n        allowed_rgb_res_base = list(range(input_res_base, output_res_base))\n        return [*map(lambda p: 2**p, allowed_rgb_res_base)]\n\n    @property\n    def device(self):\n        return self.style_network.net[0].weight.device\n\n    @property\n    def total_params(self):\n        return sum([p.numel() for p in self.parameters()])\n\n    def resize_image_to(self, x, size):\n        return F.interpolate(x, (size, size), mode=self.resize_mode)\n\n    def forward(\n        self,\n        lowres_image: torch.Tensor,\n        styles: Optional[torch.Tensor] = None,\n        noise: Optional[torch.Tensor] = None,\n        global_text_tokens: Optional[torch.Tensor] = None,\n        return_all_rgbs: bool = False,\n    ):\n        x = lowres_image\n\n        noise_scale = 0.001  # Adjust the scale of the noise as needed\n        noise_aug = torch.randn_like(x) * noise_scale\n        x = x + noise_aug\n        x = x.clamp(0, 1)\n\n        shape = x.shape\n        batch_size = shape[0]\n\n        assert shape[-2:] == ((self.input_image_size,) * 2)\n\n        # styles\n        if not exists(styles):\n            assert exists(self.style_network)\n\n            noise = default(\n                noise,\n                torch.randn(\n                    (batch_size, self.style_network.dim_in), device= self.device\n                ),\n            )\n            styles = self.style_network(noise, global_text_tokens)\n\n        # project styles to conv modulations\n        conv_mods = self.style_to_conv_modulations(styles)\n        conv_mods = conv_mods.split(self.style_embed_split_dims, dim=-1)\n        conv_mods = iter(conv_mods)\n\n        x = self.init_conv(x)\n\n        h = []\n        for blocks, (attn, downsample) in self.downs:\n            for block in blocks:\n                x = block(x, conv_mods_iter=conv_mods)\n                h.append(x)\n\n            if attn is not None:\n                x = attn(x)\n\n            x = downsample(x)\n\n        x = self.mid_block1(x, conv_mods_iter=conv_mods)\n        x = self.mid_attn(x)\n        x = self.mid_block2(x, conv_mods_iter=conv_mods)\n\n        for (\n            blocks,\n            (\n                upsample,\n                attn,\n            ),\n        ) in self.ups:\n            x = upsample(x)\n            for block in blocks:\n                if h != []:\n                    res = h.pop()\n                    res = res * self.skip_connect_scale\n                    x = torch.cat((x, res), dim=1)\n\n                x = block(x, conv_mods_iter=conv_mods)\n\n            if attn is not None:\n                x = attn(x)\n\n        x = self.final_res_block(x, conv_mods_iter=conv_mods)\n        rgb = self.final_to_rgb(x)\n\n        if not return_all_rgbs:\n            return rgb\n\n        return rgb, []\n\n\ndef tile_image(image, chunk_size=64):\n    c, h, w = image.shape\n    h_chunks = ceil(h / chunk_size)\n    w_chunks = ceil(w / chunk_size)\n    tiles = []\n    for i in range(h_chunks):\n        for j in range(w_chunks):\n            tile = image[:, i * chunk_size:(i + 1) * chunk_size, j * chunk_size:(j + 1) * chunk_size]\n            tiles.append(tile)\n    return tiles, h_chunks, w_chunks\n\n# This helps create a checkboard pattern with some edge blending\ndef create_checkerboard_weights(tile_size):\n    x = torch.linspace(-1, 1, tile_size)\n    y = torch.linspace(-1, 1, tile_size)\n\n    x, y = torch.meshgrid(x, y, indexing='ij')\n    d = torch.sqrt(x*x + y*y)\n    sigma, mu = 0.5, 0.0\n    weights = torch.exp(-((d-mu)**2 / (2.0 * sigma**2)))\n\n    # saturate the values to sure get high weights in the center\n    weights = weights**8\n\n    return weights / weights.max()  # Normalize to [0, 1]\n\ndef repeat_weights(weights, image_size):\n    tile_size = weights.shape[0]\n    repeats = (math.ceil(image_size[0] / tile_size), math.ceil(image_size[1] / tile_size))\n    return weights.repeat(repeats)[:image_size[0], :image_size[1]]\n\ndef create_offset_weights(weights, image_size):\n    tile_size = weights.shape[0]\n    offset = tile_size // 2\n    full_weights = repeat_weights(weights, (image_size[0] + offset, image_size[1] + offset))\n    return full_weights[offset:, offset:]\n\ndef merge_tiles(tiles, h_chunks, w_chunks, chunk_size=64):\n    # Determine the shape of the output tensor\n    c = tiles[0].shape[0]\n    h = h_chunks * chunk_size\n    w = w_chunks * chunk_size\n\n    # Create an empty tensor to hold the merged image\n    merged = torch.zeros((c, h, w), dtype=tiles[0].dtype)\n\n    # Iterate over the tiles and place them in the correct position\n    for idx, tile in enumerate(tiles):\n        i = idx // w_chunks\n        j = idx % w_chunks\n\n        h_start = i * chunk_size\n        w_start = j * chunk_size\n\n        tile_h, tile_w = tile.shape[1:]\n        merged[:, h_start:h_start+tile_h, w_start:w_start+tile_w] = tile\n\n    return merged\n\nclass AuraSR:\n    def __init__(self, config: dict[str, Any], device: str = \"cuda\"):\n        self.upsampler = UnetUpsampler(**config).to(device)\n        self.input_image_size = config[\"input_image_size\"]\n\n    @classmethod\n    def from_pretrained(cls, model_id: str = \"fal-ai/AuraSR\", use_safetensors: bool = True, device: str = \"cuda\"):\n        import json\n        import torch\n        from pathlib import Path\n        from huggingface_hub import snapshot_download\n\n        # Check if model_id is a local file\n        if Path(model_id).is_file():\n            local_file = Path(model_id)\n            if local_file.suffix == '.safetensors':\n                use_safetensors = True\n            elif local_file.suffix == '.ckpt':\n                use_safetensors = False\n            else:\n                raise ValueError(f\"Unsupported file format: {local_file.suffix}. Please use .safetensors or .ckpt files.\")\n\n            # For local files, we need to provide the config separately\n            config_path = local_file.with_name('config.json')\n            if not config_path.exists():\n                raise FileNotFoundError(\n                    f\"Config file not found: {config_path}. \"\n                    f\"When loading from a local file, ensure that 'config.json' \"\n                    f\"is present in the same directory as '{local_file.name}'. \"\n                    f\"If you're trying to load a model from Hugging Face, \"\n                    f\"please provide the model ID instead of a file path.\"\n                )\n\n            config = json.loads(config_path.read_text())\n            hf_model_path = local_file.parent\n        else:\n            hf_model_path = Path(snapshot_download(model_id))\n            config = json.loads((hf_model_path / \"config.json\").read_text())\n\n        model = cls(config, device)\n\n        if use_safetensors:\n            try:\n                from safetensors.torch import load_file\n                checkpoint = load_file(hf_model_path / \"model.safetensors\" if not Path(model_id).is_file() else model_id)\n            except ImportError:\n                raise ImportError(\n                    \"The safetensors library is not installed. \"\n                    \"Please install it with `pip install safetensors` \"\n                    \"or use `use_safetensors=False` to load the model with PyTorch.\"\n                )\n        else:\n            checkpoint = torch.load(hf_model_path / \"model.ckpt\" if not Path(model_id).is_file() else model_id)\n\n        model.upsampler.load_state_dict(checkpoint, strict=True)\n        return model\n    @torch.no_grad()\n    def upscale_2x(self, image: Image.Image, max_batch_size=8) -> Image.Image:\n        tensor_transform = transforms.ToTensor()\n        device = self.upsampler.device\n    \n        image_tensor = tensor_transform(image).unsqueeze(0)\n        _, _, h, w = image_tensor.shape\n        pad_h = (self.input_image_size - h % self.input_image_size) % self.input_image_size\n        pad_w = (self.input_image_size - w % self.input_image_size) % self.input_image_size\n    \n        # Pad the image\n        image_tensor = torch.nn.functional.pad(image_tensor, (0, pad_w, 0, pad_h), mode='reflect').squeeze(0)\n        tiles, h_chunks, w_chunks = tile_image(image_tensor, self.input_image_size)\n    \n        # Batch processing of tiles\n        num_tiles = len(tiles)\n        batches = [tiles[i:i + max_batch_size] for i in range(0, num_tiles, max_batch_size)]\n        reconstructed_tiles = []\n    \n        for batch in batches:\n            model_input = torch.stack(batch).to(device)\n            generator_output = self.upsampler(\n                lowres_image=model_input,\n                noise=torch.randn(model_input.shape[0], 128, device=device)\n            )\n            reconstructed_tiles.extend(list(generator_output.clamp_(0, 1).detach().cpu()))\n    \n        merged_tensor = merge_tiles(reconstructed_tiles, h_chunks, w_chunks, self.input_image_size * 2)\n        unpadded = merged_tensor[:, :h * 2, :w * 2]\n    \n        to_pil = transforms.ToPILImage()\n        return to_pil(unpadded)\n\n    @torch.no_grad()\n    def upscale_4x(self, image: Image.Image, max_batch_size=8) -> Image.Image:\n        tensor_transform = transforms.ToTensor()\n        device = self.upsampler.device\n\n        image_tensor = tensor_transform(image).unsqueeze(0)\n        _, _, h, w = image_tensor.shape\n        pad_h = (self.input_image_size - h % self.input_image_size) % self.input_image_size\n        pad_w = (self.input_image_size - w % self.input_image_size) % self.input_image_size\n\n        # Pad the image\n        image_tensor = torch.nn.functional.pad(image_tensor, (0, pad_w, 0, pad_h), mode='reflect').squeeze(0)\n        tiles, h_chunks, w_chunks = tile_image(image_tensor, self.input_image_size)\n\n        # Batch processing of tiles\n        num_tiles = len(tiles)\n        batches = [tiles[i:i + max_batch_size] for i in range(0, num_tiles, max_batch_size)]\n        reconstructed_tiles = []\n\n        for batch in batches:\n            model_input = torch.stack(batch).to(device)\n            generator_output = self.upsampler(\n                lowres_image=model_input,\n                noise=torch.randn(model_input.shape[0], 128, device=device)\n            )\n            reconstructed_tiles.extend(list(generator_output.clamp_(0, 1).detach().cpu()))\n\n        merged_tensor = merge_tiles(reconstructed_tiles, h_chunks, w_chunks, self.input_image_size * 4)\n        unpadded = merged_tensor[:, :h * 4, :w * 4]\n\n        to_pil = transforms.ToPILImage()\n        return to_pil(unpadded)\n    # Tiled 4x upscaling with overlapping tiles to reduce seam artifacts\n    # weights options are 'checkboard' and 'constant'\n    @torch.no_grad()\n    def upscale_4x_overlapped(self, image, max_batch_size=16, weight_type='checkboard'):\n        tensor_transform = transforms.ToTensor()\n        device = self.upsampler.device\n\n        image_tensor = tensor_transform(image).unsqueeze(0)\n        _, _, h, w = image_tensor.shape\n\n        # Calculate paddings\n        pad_h = (\n            self.input_image_size - h % self.input_image_size\n        ) % self.input_image_size\n        pad_w = (\n            self.input_image_size - w % self.input_image_size\n        ) % self.input_image_size\n\n        pad_h = min(pad_h-1, self.input_image_size-1)\n        pad_w = min(pad_w-1, self.input_image_size-1)\n        # Pad the image\n        image_tensor = torch.nn.functional.pad(\n            image_tensor, (0, pad_w, 0, pad_h), mode=\"reflect\"\n        ).squeeze(0)\n\n        # Function to process tiles\n        def process_tiles(tiles, h_chunks, w_chunks):\n            num_tiles = len(tiles)\n            batches = [\n                tiles[i : i + max_batch_size]\n                for i in range(0, num_tiles, max_batch_size)\n            ]\n            reconstructed_tiles = []\n\n            for batch in batches:\n                model_input = torch.stack(batch).to(device)\n                generator_output = self.upsampler(\n                    lowres_image=model_input,\n                    noise=torch.randn(model_input.shape[0], 128, device=device),\n                )\n                reconstructed_tiles.extend(\n                    list(generator_output.clamp_(0, 1).detach().cpu())\n                )\n\n            return merge_tiles(\n                reconstructed_tiles, h_chunks, w_chunks, self.input_image_size\n            )\n\n        # First pass\n        tiles1, h_chunks1, w_chunks1 = tile_image(image_tensor, self.input_image_size)\n        result1 = process_tiles(tiles1, h_chunks1, w_chunks1)\n\n        # Second pass with offset\n        offset = self.input_image_size // 2\n        image_tensor_offset = torch.nn.functional.pad(image_tensor, (offset, offset, offset, offset), mode='reflect').squeeze(0)\n\n        tiles2, h_chunks2, w_chunks2 = tile_image(\n            image_tensor_offset, self.input_image_size\n        )\n        result2 = process_tiles(tiles2, h_chunks2, w_chunks2)\n\n        # unpad\n        offset_4x = offset * 1\n        result2_interior = result2[:, offset_4x:-offset_4x, offset_4x:-offset_4x]\n\n        if weight_type == 'checkboard':\n            weight_tile = create_checkerboard_weights(self.input_image_size * 1)\n\n            weight_shape = result2_interior.shape[1:]\n            weights_1 = create_offset_weights(weight_tile, weight_shape)\n            weights_2 = repeat_weights(weight_tile, weight_shape)\n\n            normalizer = weights_1 + weights_2\n            weights_1 = weights_1 / normalizer\n            weights_2 = weights_2 / normalizer\n\n            weights_1 = weights_1.unsqueeze(0).repeat(3, 1, 1)\n            weights_2 = weights_2.unsqueeze(0).repeat(3, 1, 1)\n        elif weight_type == 'constant':\n            weights_1 = torch.ones_like(result2_interior) * 0.5\n            weights_2 = weights_1\n        else:\n            raise ValueError(\"weight_type should be either 'gaussian' or 'constant' but got\", weight_type)\n\n        result1 = result1 * weights_2\n        result2 = result2_interior * weights_1\n\n        # Average the overlapping region\n        result1 = (\n            result1 + result2\n        )\n\n        # Remove padding\n        unpadded = result1[:, : h, : w]\n\n        to_pil = transforms.ToPILImage()\n        return to_pil(unpadded)","metadata":{"trusted":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-11-28T11:56:36.225531Z","iopub.execute_input":"2024-11-28T11:56:36.225862Z","iopub.status.idle":"2024-11-28T11:56:40.980330Z","shell.execute_reply.started":"2024-11-28T11:56:36.225814Z","shell.execute_reply":"2024-11-28T11:56:40.979393Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"os.mkdir('testgradcam')\nos.chdir('testgradcam')\nos.mkdir('test')\nos.mkdir('train')\nos.chdir('test')\nos.mkdir('FAKE')\nos.mkdir('REAL')\nos.chdir('..')\nos.chdir('train')\nos.mkdir('FAKE')\nos.mkdir('REAL')\nos.chdir('..')\nos.chdir('..')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:56:40.981449Z","iopub.execute_input":"2024-11-28T11:56:40.981972Z","iopub.status.idle":"2024-11-28T11:56:40.987430Z","shell.execute_reply.started":"2024-11-28T11:56:40.981911Z","shell.execute_reply":"2024-11-28T11:56:40.986617Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import requests\nfrom io import BytesIO\nfrom PIL import Image\nimport os\nimport cv2\nfrom PIL import Image\nimport numpy as np\naura_sr = AuraSR.from_pretrained()\ndef load_image_from_url(url):\n    response = requests.get(url)\n    image_data = BytesIO(response.content)\n    return Image.open(image_data)\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-28T11:56:40.989612Z","iopub.execute_input":"2024-11-28T11:56:40.989863Z","iopub.status.idle":"2024-11-28T11:58:22.633534Z","shell.execute_reply.started":"2024-11-28T11:56:40.989840Z","shell.execute_reply":"2024-11-28T11:58:22.632547Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ba558adeb64c1096575e9b1fad06da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE.md:   0%|          | 0.00/18.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b04710d8294039bd632f7d955d3052"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ba7c06f5464f1984c1c3d8173e6aff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1428cfe601d4d0dbb237a0f0aa7011c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/983 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a774ef6d1b54fe391af44f9ed49e383"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.ckpt:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8ca2a2b47874502804dd13c51183e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0015638c5ffb489786a8ff00df90f87c"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet50\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\nimport os\n\ndef load_model(model_path, device='cuda'):\n    model = resnet50(pretrained=False)\n    model.fc = nn.Linear(model.fc.in_features, 2)\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n    model.eval()\n    return model\ndef generate_intensity_matrix(grayscale_cam, size=(32, 32)):\n    # Resize the grayscale CAM to desired dimensions\n    intensity_matrix = cv2.resize(grayscale_cam, size, interpolation=cv2.INTER_LINEAR)\n    # Values are already normalized between 0 and 1 from GradCAM\n    return intensity_matrix\n\ndef generate_gradcam_visualizations(\n    model_path,\n    dataset_path,\n    output_dir,\n    num_samples=1,  # Changed to 1 for testing\n    device='cuda'\n):\n    # Create output directory\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Load model\n    model = load_model(model_path, device)\n\n    # Define target layer for GradCAM\n    target_layers = [model.layer4[-1]]\n    # Initialize GradCAM\n    cam = GradCAM(\n        model=model,\n        target_layers=target_layers,\n    )\n\n    # Setup data loading\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load dataset\n    dataset = torchvision.datasets.ImageFolder(\n        root=dataset_path,\n        transform=transform\n    )\n\n    # Select random samples\n    num_samples = min(num_samples, len(dataset))\n    indices = torch.randperm(len(dataset))[:num_samples]\n\n    # Process each image\n    for idx in tqdm(indices, desc=\"Generating Grad-CAM visualizations\"):\n        # Get image and label\n        img_tensor, label = dataset[idx]\n        input_tensor = img_tensor.unsqueeze(0)\n\n        # Get original image for overlay\n        img_path = dataset.imgs[idx][0]\n        rgb_img = cv2.imread(img_path, 1)[:, :, ::-1]\n        rgb_img = cv2.resize(rgb_img, (224, 224))\n        rgb_img = np.float32(rgb_img) / 255\n\n        # Generate class activation map\n        grayscale_cam = cam(input_tensor=input_tensor, targets=None)\n        grayscale_cam = grayscale_cam[0, :]\n\n        # Generate 32x32 intensity matrix\n        intensity_matrix = generate_intensity_matrix(grayscale_cam)\n\n        # Save intensity matrix\n        matrix_output_path = os.path.join(\n            output_dir,\n            f\"intensity_matrix_{0}.npy\"\n        )\n        np.save(matrix_output_path, intensity_matrix)\n\n        # Print shape and some statistics of the intensity matrix\n        print(f\"Intensity Matrix Shape: {intensity_matrix.shape}\")\n        print(f\"Min value: {intensity_matrix.min():.4f}\")\n        print(f\"Max value: {intensity_matrix.max():.4f}\")\n        print(f\"Mean value: {intensity_matrix.mean():.4f}\")\n\n        # Overlay CAM on original image\n        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n\n        # Get model prediction\n        with torch.no_grad():\n            output = model(input_tensor.to(device))\n            pred = output.argmax(dim=1).item()\n\n        # Save the visualization\n        output_path = os.path.join(\n            output_dir,\n            f\"gradcam_{idx}_pred{pred}_true{label}.jpg\"\n        )\n        cv2.imwrite(output_path, visualization[:, :, ::-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:58:22.634719Z","iopub.execute_input":"2024-11-28T11:58:22.635019Z","iopub.status.idle":"2024-11-28T11:58:23.405474Z","shell.execute_reply.started":"2024-11-28T11:58:22.634980Z","shell.execute_reply":"2024-11-28T11:58:23.404547Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport torch\nfrom transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\n\nclass Filter():\n    def __init__(self, csv_path =\"/kaggle/input/artifact-interiit/Artifact_Description.csv\", \n                 model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\"), \n                 processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")):\n        self.csv_path = csv_path\n        \n        self.data = pd.read_csv(csv_path, on_bad_lines=\"skip\")\n        \n        # Load CLIP model and processor\n        self.model = model\n        self.processor = processor\n        \n        # Prepare artifact descriptions\n        self.artifact_texts = data['Artifact'] + \": \" + data['Description']\n        self.inputs_text = processor(text=artifact_texts.tolist(), return_tensors=\"pt\", padding=True)\n        \n        # Extract text features\n        with torch.no_grad():\n            self.text_features = model.get_text_features(**inputs_text)\n\n# Function to extract image features\n    def get_image_features(self, image_path):\n        # Load the image using Pillow\n        image = Image.open(image_path).convert(\"RGB\")\n        # Process the image\n        inputs_image = self.processor(images=image, return_tensors=\"pt\")\n        with torch.no_grad():\n            image_features = self.model.get_image_features(**inputs_image)\n        return image_features\n    \n    # Compare image features with artifact text features and save results\n    def find_artifacts(self, image_path, k=5):\n        image_features = self.get_image_features(image_path)\n        similarities = torch.nn.functional.cosine_similarity(image_features, self.text_features)\n        top_k_indices = similarities.topk(k).indices\n        top_k_similarities = similarities[top_k_indices].cpu().numpy()\n        results = data.iloc[top_k_indices].copy()\n        results['Cosine_Similarity'] = top_k_similarities\n        return results\n    \n    # Process all images in a folder and save results to a JSON file\n    def filter_artifacts(self, image_folder, output_json = \"image_text_results.json\", k=10):\n        results_dict = {}\n        \n        for image_name in os.listdir(image_folder):\n            image_path = os.path.join(image_folder, image_name)\n            \n            if os.path.isfile(image_path):  # Ensure it's a file\n                print(f\"Processing: {image_name}\")\n                \n                try:\n                    top_artifacts = self.find_artifacts(image_path, k=k)\n                    # Convert DataFrame to a dictionary format for JSON serialization\n                    results_dict[image_name] = top_artifacts.to_dict(orient='records')\n                except Exception as e:\n                    print(f\"Error processing {image_name}: {e}\")\n        \n        # Save the results dictionary to a JSON file\n        with open(output_json, 'w') as json_file:\n            json.dump(results_dict, json_file, indent=4)\n        print(f\"Results saved to {output_json}\")\n    \n    # Define the folder path and output JSON file\n    # image_folder = \"/kaggle/input/random-mirror-lady-fake-lol\"  # Replace with your folder path\n    # output_json = \"/kaggle/working/top_artifacts.json\"\n    \n    # Run the folder processing\n    # process_folder(image_folder, output_json, k=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:58:23.406844Z","iopub.execute_input":"2024-11-28T11:58:23.407293Z","iopub.status.idle":"2024-11-28T11:59:08.054944Z","shell.execute_reply.started":"2024-11-28T11:58:23.407266Z","shell.execute_reply":"2024-11-28T11:59:08.054255Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ef74da5b1d4f3dba896ee0b4458500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7c6c380a27f4b6aa141d57450b0d80a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cc498f72f944c10b8f5398124ae2d2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ef2f818244415688ca24e007265483"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5038234570e44d292424f5f2b0c6585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eb6895c523b402bafa66b9bc5c3aed2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e95ef41ae62438c8be7d045c4fdab66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e978fb9173234ce8ba0bb8521baa742d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b146d876751d48d3ab304b9e5e9ce6b1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from PIL import Image\n# from PIL import Image\nimport cv2\n\ndef process_img_final(image_path):\n    # image = cv2.imread(image_path)\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = Image.open(image_path)\n    # img = Image(\"/kaggle/input/pegasus/Screenshot 2024-11-24 161819.png\")\n    image = image.resize((32,32))\n    image_2 = Image.fromarray(np.vstack((np.hstack((image,image)), np.hstack((image,image)))))\n    # image.save(\"cropped_image.png\")\n    image.save(\"/kaggle/working/testgradcam/test/FAKE/peg32.png\")\n    image.save(\"/kaggle/working/testgradcam/test/REAL/peg32.png\")\n    \n    image.save(\"/kaggle/working/testgradcam/train/FAKE/peg32.png\")\n    image.save(\"/kaggle/working/testgradcam/train/REAL/peg32.png\")\n    \n    # # Load your 32x32 image (replace with your image path)\n    # # image = Image.new(\"RGB\", (32, 32), color=\"red\")  # Example red image\n    \n    # # Calculate padding\n    # pad_size = (48 - 32) // 2  # 8 pixels on each side\n    \n    # # Add padding\n    # padded_image = Image.new(\"RGB\", (48, 48), color=(0, 0, 0))  # Black padding\n    # padded_image.paste(image, (pad_size, pad_size))  # Paste the original image centered\n    \n    # # Show the padded image\n    # print(padded_image.size)\n    # # import matplotlib.pyplot as plt\n    # # for i in range(len(cifar10)):\n    # #   img, label = cifar10[i]\n    upscaled_image = aura_sr.upscale_4x(image_2)\n    # upscaled_image = aura_sr.upscale_4x(upscaled_image)\n    # # upscaled_image = cv2.resize(np.array(upscaled_image), (32,32), interpolation=cv2.INTER_CUBIC)\n    # # cv2.imwrite(\"pegasus_aursr.png\", upscaled_image)\n    # # Image.save(\"pegasus_aursr\", upscaled_image)\n    # upscaled_image.save(\"pegasus_aursr.png\")\n    # print(upscaled_image.size)\n    # upscaled_image\n    #   # if i%100 == 0:\n    #   #   print(i)\n    # # from PIL import Image\n    \n    # # Open your 192x192 image (replace with your actual image path)\n    # image = Image.open(\"/kaggle/working/pegasus_aursr.png\")\n    # print(image.size)\n    # # Calculate the center coordinates\n    # width, height = image.size\n    # crop_size = 512\n    # left = (width - crop_size) // 2\n    # top = (height - crop_size) // 2\n    # right = (width + crop_size) // 2\n    # bottom = (height + crop_size) // 2\n    \n    # # Crop the image\n    cropped_image = upscaled_image.crop((0, 0, 128, 128))\n    \n    # # Save or show the cropped image\n    cropped_image.save(\"cropped_image.png\")\n    # # cropped_image\ndef process_img_final_32(image_path):\n    # image = cv2.imread(image_path)\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = Image.open(image_path)\n    # img = Image(\"/kaggle/input/pegasus/Screenshot 2024-11-24 161819.png\")\n    image = image.resize((32,32))\n    image_2 = Image.fromarray(np.vstack((np.hstack((image,image)), np.hstack((image,image)))))\n    # image.save(\"cropped_image.png\")\n    image.save(\"/kaggle/working/testgradcam/test/FAKE/peg32.png\")\n    image.save(\"/kaggle/working/testgradcam/test/REAL/peg32.png\")\n    \n    image.save(\"/kaggle/working/testgradcam/train/FAKE/peg32.png\")\n    image.save(\"/kaggle/working/testgradcam/train/REAL/peg32.png\")\n    \n    # # Load your 32x32 image (replace with your image path)\n    # # image = Image.new(\"RGB\", (32, 32), color=\"red\")  # Example red image\n    \n    # # Calculate padding\n    # pad_size = (48 - 32) // 2  # 8 pixels on each side\n    \n    # # Add padding\n    # padded_image = Image.new(\"RGB\", (48, 48), color=(0, 0, 0))  # Black padding\n    # padded_image.paste(image, (pad_size, pad_size))  # Paste the original image centered\n    \n    # # Show the padded image\n    # print(padded_image.size)\n    # # import matplotlib.pyplot as plt\n    # # for i in range(len(cifar10)):\n    # #   img, label = cifar10[i]\n    # upscaled_image = aura_sr.upscale_4x(image_2)\n    # upscaled_image = aura_sr.upscale_4x(upscaled_image)\n    # # upscaled_image = cv2.resize(np.array(upscaled_image), (32,32), interpolation=cv2.INTER_CUBIC)\n    # # cv2.imwrite(\"pegasus_aursr.png\", upscaled_image)\n    # # Image.save(\"pegasus_aursr\", upscaled_image)\n    # upscaled_image.save(\"pegasus_aursr.png\")\n    # print(upscaled_image.size)\n    # upscaled_image\n    #   # if i%100 == 0:\n    #   #   print(i)\n    # # from PIL import Image\n    \n    # # Open your 192x192 image (replace with your actual image path)\n    # image = Image.open(\"/kaggle/working/pegasus_aursr.png\")\n    # print(image.size)\n    # # Calculate the center coordinates\n    # width, height = image.size\n    # crop_size = 512\n    # left = (width - crop_size) // 2\n    # top = (height - crop_size) // 2\n    # right = (width + crop_size) // 2\n    # bottom = (height + crop_size) // 2\n    \n    # # Crop the image\n    # cropped_image = upscaled_image.crop((0, 0, 128, 128))\n    \n    # # Save or show the cropped image\n    image.save(\"cropped_image.png\")\n    # # cropped_image\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:05:24.150763Z","iopub.execute_input":"2024-11-28T13:05:24.151131Z","iopub.status.idle":"2024-11-28T13:05:24.164266Z","shell.execute_reply.started":"2024-11-28T13:05:24.151099Z","shell.execute_reply":"2024-11-28T13:05:24.163435Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"import json\nimport clip\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom PIL import Image\n\n# Load CLIP model\n\nclass Final():\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.model, self.preprocess = clip.load(\"ViT-B/32\", device=self.device)\n        self.data = pd.read_csv(\"/kaggle/input/artifact-interiit/Artifact_Description.csv\", on_bad_lines=\"skip\")\n    # def load_descriptions_from_json(json_path, top_n=10):\n    #     \"\"\"\n    #     Load top N descriptions from the JSON file.\n    #     \"\"\"\n    #     with open(json_path, \"r\") as f:\n    #         data = json.load(f)\n        \n    #     # Collect the top N descriptions\n    #     descriptions = []\n    #     for image_name, artifacts in data.items():\n    #         descriptions.extend(list(artifacts.keys())[:top_n])\n        \n    #     return list(set(descriptions))  # Deduplicate descriptions\n    \n    \n    def image_text_search(self, image_patches, text_descriptions):\n        \"\"\"\n        Compute text-image similarity for each patch and return scores.\n        \"\"\"\n        text = clip.tokenize(text_descriptions).to(self.device)\n        patch_results = []\n    \n        for patch in image_patches:\n            patch = self.preprocess(patch).unsqueeze(0).to(self.device)\n            with torch.no_grad():\n                logits_per_image, _ = self.model(patch, text)\n                probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n            patch_results.append(probs[0])\n        \n        return np.array(patch_results)  # Shape: (num_patches, num_descriptions)\n    \n    \n    def split_image_into_patches(self, image, patch_size, intensities):\n        \"\"\"\n        Split the image into non-overlapping patches of size (patch_size x patch_size).\n        \"\"\"\n        image = np.array(image)\n        h, w, c = image.shape\n        patches = []\n        intensity = []\n        for i in range(0, h, patch_size):\n            for j in range(0, w, patch_size):\n                patch = image[i : i + patch_size, j : j + patch_size]\n                gradpatch = intensities[i : i + patch_size, j : j + patch_size]\n                if patch.shape[:2] == (patch_size, patch_size):  # Ensure patch size\n                    patches.append(Image.fromarray(patch))\n                    intensity.append(np.sum(gradpatch))\n        return patches, intensity\n    \n    # def patch_weight(i, j, image, intensity)\n    \n    \n    def give_result(self, patch_results, text_descriptions, patch_weights):\n        \"\"\"\n        Perform majority voting to determine the most frequent description.\n        \"\"\"\n        votes = np.argmax(patch_results, axis=1)  # Get index of max similarity for each patch\n        weighted_avg = (votes==0)*patch_weights / ((votes!=2)*patch_weights)\n        # unique, counts = np.unique(votes, return_counts=True)  # Count occurrences\n        # majority_index = unique[np.argmax(counts)]  # Get the index with the highest count\n        return weighted_avg\n    \n    \n    def overall_majority_vote(self, results, text_descriptions):\n        \"\"\"\n        Perform a majority vote across patch sizes.\n        \"\"\"\n        all_votes = np.concatenate([np.argmax(res, axis=1) for res in results])\n        unique, counts = np.unique(all_votes, return_counts=True)\n        majority_index = unique[np.argmax(counts)]\n        return text_descriptions[majority_index], dict(zip(unique, counts))\n    \n    def give_result(self, patch_results, text_descriptions, patch_weights):\n        \"\"\"\n        Perform majority voting to determine the most frequent description.\n        \"\"\"\n        votes = np.argmax(patch_results, axis=1)  # Get index of max similarity for each patch\n        if (np.sum((votes!=2)*patch_weights)!=0):\n            weighted_avg = np.sum((votes==0)*patch_weights) / np.sum((votes!=2)*patch_weights)\n        else:\n            weighted_avg = 0\n        # unique, counts = np.unique(votes, return_counts=True)  # Count occurrences\n        # majority_index = unique[np.argmax(counts)]  # Get the index with the highest count\n        return weighted_avg\n    \n    def final_img_process(self, description_list):\n        \n        # Load descriptions from the JSON file\n        json_path = \"image_text_results.json\"  # Path to the JSON file\n        # descriptions = load_descriptions_from_json(json_path, top_n=10)\n        descriptions = description_list\n        \n        # Parameters\n        patch_sizes = [16, 32, 64, 128, 256]  # Patch sizes to process\n        \n        # Load and preprocess the image\n        # image = cv2.imread(\"/kaggle/working/cropped_image.png\")\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = Image.open(\"/kaggle/working/cropped_image.png\")\n        intensity = np.load(\"/kaggle/working/gradcam_visualizations/intensity_matrix_0.npy\")\n        intensity = np.array(Image.fromarray(intensity).resize((512,512)))\n        # Process the image with each patch size\n        all_results = []\n        all_weights = []\n        for patch_size in patch_sizes:\n            patches, patch_intensity = self.split_image_into_patches(image, patch_size, intensity)\n            patch_results = self.image_text_search(patches, descriptions)\n            all_results.append(list(patch_results))\n            all_weights.append(patch_intensity)\n        \n        # all_results[0].shape\n        \n        # allnp.array([i for j in all_results for i in j])\n        # # Perform majority voting for each patch size\n        # individual_results = []\n        \n        stacked_results = np.array([i for j in all_results for i in j])\n        stacked_weights = np.array([i for j in all_weights for i in j])\n        \n        \n        # # for i, patch_results in enumerate(all_results):\n        weighted_avg = self.give_result(stacked_results, descriptions, stacked_weights)\n        #     # individual_results.append((patch_sizes[i], label, patch_votes))\n        #     # print(f\"Patch Size: {patch_sizes[i]}, Final Label: {label}, Patch Votes: {patch_votes}\")\n        \n        # # Perform overall majority voting across all patch sizes\n        # # final_label, overall_votes = overall_majority_vote(all_results, descriptions)\n        \n        # Display the image with final results\n        # plt.imshow(np.array(image))\n        # title_string = f\"Final Label: {final_label}\\nOverall Votes: {overall_votes}\"\n        # plt.title(title_string)\n        # plt.axis(\"off\")\n        # plt.show()\n        \n        # print(weighted_avg)\n        return weighted_avg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:21:08.157444Z","iopub.execute_input":"2024-11-28T12:21:08.157816Z","iopub.status.idle":"2024-11-28T12:21:08.175439Z","shell.execute_reply.started":"2024-11-28T12:21:08.157781Z","shell.execute_reply":"2024-11-28T12:21:08.174586Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def setup_image(img_path):\n    process_img_final(img_path)\n    generate_gradcam_visualizations(\n        model_path='/kaggle/input/forgradcam/pytorch/default/1/fake_detector.pth',\n        dataset_path='/kaggle/working/testgradcam',\n        output_dir='gradcam_visualizations',\n        num_samples=1,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n\ndef setup_image_32(img_path):\n    process_img_final_32(img_path)\n    generate_gradcam_visualizations(\n        model_path='/kaggle/input/forgradcam/pytorch/default/1/fake_detector.pth',\n        dataset_path='/kaggle/working/testgradcam',\n        output_dir='gradcam_visualizations',\n        num_samples=1,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:07:43.487185Z","iopub.execute_input":"2024-11-28T13:07:43.487825Z","iopub.status.idle":"2024-11-28T13:07:43.492990Z","shell.execute_reply.started":"2024-11-28T13:07:43.487781Z","shell.execute_reply":"2024-11-28T13:07:43.492202Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# filter = Filter()\n# filter.filter_artifacts(\"/kaggle/input/cifake-test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:21:08.517392Z","iopub.execute_input":"2024-11-28T12:21:08.517686Z","iopub.status.idle":"2024-11-28T12:21:08.521752Z","shell.execute_reply.started":"2024-11-28T12:21:08.517658Z","shell.execute_reply":"2024-11-28T12:21:08.520794Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def extract_probable_artifacts_from_JSON(filename, json_file_path = \"image_text_results.json\"):\n    \n    try:\n        # Load JSON data from the file\n        with open(json_file_path, 'r') as file:\n            data = json.load(file)\n        \n        # Extract artifacts for the given filename\n        if filename in data:\n            return [entry[\"Artifact\"] for entry in data[filename]]\n        else:\n            return []\n    except FileNotFoundError:\n        print(f\"Error: File not found at {json_file_path}\")\n        return []\n    except json.JSONDecodeError:\n        print(\"Error: Invalid JSON format\")\n        return []\n    \n    \ndef find_artifacts_in_image(folder_path, threshold = 0.5):\n    sr_artifacts = [\n        \"Incorrect reflection mapping\",\n        \"Abruptly cut off objects\",\n        \"Ghosting effects: Semi-transparent duplicates of elements\",\n        \"Dental anomalies in mammals\",\n        \"Anatomically incorrect paw structures\",\n        \"Unrealistic eye reflections\",\n        \"Misshapen ears or appendages\",\n        \"Unnatural pose artifacts\",\n        \"Biological asymmetry errors\",\n        \"Impossible foreshortening in animal bodies\",\n        \"Impossible mechanical connections\",\n        \"Impossible mechanical joints\",\n        \"Physically impossible structural elements\",\n        \"Incorrect wheel geometry\",\n        \"Implausible aerodynamic structures\",\n        \"Misaligned body panels\",\n        \"Distorted window reflections\",\n        \"Anatomically impossible joint configurations\",\n        \"Non-manifold geometries in rigid structures\",\n        \"Asymmetric features in naturally symmetric objects\",\n        \"Misaligned bilateral elements in animal faces\",\n        \"Irregular proportions in mechanical components\",\n        \"Inconsistent scale of mechanical parts\",\n        \"Incorrect perspective rendering\",\n        \"Scale inconsistencies within single objects\",\n        \"Spatial relationship errors\",\n        \"Scale inconsistencies within the same object class\",\n        \"Depth perception anomalies\"\n    ]\n\n    tuple_desc = pd.read_csv('/kaggle/input/simplified-tuple-artifact/simplified_artifact_descriptions.csv')\n    # filter_artifacts(folder_path)\n    # filter = Filter()\n    # filter.filter_artifacts(folder_path)\n    result = {}\n    artifact_detector = Final()\n    for filename in os.listdir(folder_path):\n        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\")):\n            # Read and preprocess the image\n            image_path = os.path.join(folder_path, filename)\n            # artifacts = extract_probable_artifacts_from_JSON(filename)\n            artifacts_present = []\n            setup_image(image_path)\n            for artifact in sr_artifacts:\n                # description = tuple_desc['Artifact'].loc(tuple_desc) #write code to get list of artifact 3 tuple\n                row = tuple_desc[tuple_desc['Artifact'] == artifact]\n                description = row.iloc[0, 1:].tolist()\n                print(description)\n                \n                score = artifact_detector.final_img_process(description)\n                if score>threshold: \n                    artifacts_present.append(artifact)\n                print(filename, \" processed for \", artifact, \" with probability of,\", score)\n                \n            result[filename] = artifacts_present\n    return result\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:21:08.630577Z","iopub.execute_input":"2024-11-28T12:21:08.631301Z","iopub.status.idle":"2024-11-28T12:21:08.639912Z","shell.execute_reply.started":"2024-11-28T12:21:08.631272Z","shell.execute_reply":"2024-11-28T12:21:08.639100Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# def find_artifacts_in_image(folder_path, threshold = 0.5):\n#     sr_artifacts = [\n#         \"Incorrect reflection mapping\",\n#         \"Abruptly cut off objects\",\n#         \"Ghosting effects: Semi-transparent duplicates of elements\",\n#         \"Dental anomalies in mammals\",\n#         \"Anatomically incorrect paw structures\",\n#         \"Unrealistic eye reflections\",\n#         \"Misshapen ears or appendages\",\n#         \"Unnatural pose artifacts\",\n#         \"Biological asymmetry errors\",\n#         \"Impossible foreshortening in animal bodies\",\n#         \"Impossible mechanical connections\",\n#         \"Impossible mechanical joints\",\n#         \"Physically impossible structural elements\",\n#         \"Incorrect wheel geometry\",\n#         \"Implausible aerodynamic structures\",\n#         \"Misaligned body panels\",\n#         \"Distorted window reflections\",\n#         \"Anatomically impossible joint configurations\",\n#         \"Non-manifold geometries in rigid structures\",\n#         \"Asymmetric features in naturally symmetric objects\",\n#         \"Misaligned bilateral elements in animal faces\",\n#         \"Irregular proportions in mechanical components\",\n#         \"Inconsistent scale of mechanical parts\",\n#         \"Incorrect perspective rendering\",\n#         \"Scale inconsistencies within single objects\",\n#         \"Spatial relationship errors\",\n#         \"Scale inconsistencies within the same object class\",\n#         \"Depth perception anomalies\"\n#     ]\n\n#     tuple_desc = pd.read_csv('/kaggle/input/simplified-tuple-artifact/simplified_artifact_descriptions.csv')\n#     # filter_artifacts(folder_path)\n#     # filter = Filter()\n#     # filter.filter_artifacts(folder_path)\n#     result = {}\n#     artifact_detector = Final()\n#     for filename in os.listdir(folder_path):\n#         if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\")):\n#             # Read and preprocess the image\n#             image_path = os.path.join(folder_path, filename)\n#             # artifacts = extract_probable_artifacts_from_JSON(filename)\n#             artifacts_present = []\n#             setup_image(image_path)\n#             for artifact in sr_artifacts:\n#                 # description = tuple_desc['Artifact'].loc(tuple_desc) #write code to get list of artifact 3 tuple\n#                 row = tuple_desc[tuple_desc['Artifact'] == artifact]\n#                 description = row.iloc[0, 1:].tolist()\n#                 print(description)\n                \n#                 score = artifact_detector.final_img_process(description)\n#                 if score>threshold: \n#                     artifacts_present.append(artifact)\n#                 print(filename, \" processed for \", artifact, \" with probability of,\", score)\n                \n#             result[filename] = artifacts_present\n#     return result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = find_artifacts_in_image(\"/kaggle/input/manually-labelled-artifacts\", 0.7)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:42:07.373876Z","iopub.execute_input":"2024-11-28T12:42:07.374491Z","iopub.status.idle":"2024-11-28T12:49:11.748182Z","shell.execute_reply.started":"2024-11-28T12:42:07.374458Z","shell.execute_reply":"2024-11-28T12:49:11.747247Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n/tmp/ipykernel_30/3602279645.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\nGenerating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 27.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0091\nMax value: 0.9982\nMean value: 0.2934\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_1.png  processed for  Incorrect reflection mapping  with probability of, 0.8156757\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_1.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_1.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.6418769\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_1.png  processed for  Dental anomalies in mammals  with probability of, 0.045781504\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_1.png  processed for  Anatomically incorrect paw structures  with probability of, 0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_1.png  processed for  Unrealistic eye reflections  with probability of, 0.09331145\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_1.png  processed for  Misshapen ears or appendages  with probability of, 0.4978294\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_1.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_1.png  processed for  Biological asymmetry errors  with probability of, 0.3772664\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_1.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.7805796\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_1.png  processed for  Impossible mechanical connections  with probability of, 0.8135727\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_1.png  processed for  Impossible mechanical joints  with probability of, 0.5191814\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_1.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_1.png  processed for  Incorrect wheel geometry  with probability of, 0.47835916\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_1.png  processed for  Implausible aerodynamic structures  with probability of, 0.45724282\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_1.png  processed for  Misaligned body panels  with probability of, 0.08551177\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_1.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_1.png  processed for  Anatomically impossible joint configurations  with probability of, 0.7260725\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_1.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.107405886\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_1.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.5037427\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_1.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 0.1782958\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_1.png  processed for  Irregular proportions in mechanical components  with probability of, 0.66744524\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_1.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.63762975\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_1.png  processed for  Incorrect perspective rendering  with probability of, 0.1511558\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_1.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_1.png  processed for  Spatial relationship errors  with probability of, 0.6586391\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_1.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_1.png  processed for  Depth perception anomalies  with probability of, 0.6282855\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 29.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2570\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_6.png  processed for  Incorrect reflection mapping  with probability of, 0.327395\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_6.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_6.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.57234985\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_6.png  processed for  Dental anomalies in mammals  with probability of, 0.16215932\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_6.png  processed for  Anatomically incorrect paw structures  with probability of, 0.0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_6.png  processed for  Unrealistic eye reflections  with probability of, 0.8156356\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_6.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_6.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_6.png  processed for  Biological asymmetry errors  with probability of, 0.6243741\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_6.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.990599\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_6.png  processed for  Impossible mechanical connections  with probability of, 0.3620374\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_6.png  processed for  Impossible mechanical joints  with probability of, 0.8754028\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_6.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_6.png  processed for  Incorrect wheel geometry  with probability of, 0.85792416\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_6.png  processed for  Implausible aerodynamic structures  with probability of, 0.6000081\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_6.png  processed for  Misaligned body panels  with probability of, 0.8216901\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_6.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_6.png  processed for  Anatomically impossible joint configurations  with probability of, 0.31260335\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_6.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.751905\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_6.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 1.0\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_6.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_6.png  processed for  Irregular proportions in mechanical components  with probability of, 0.23770401\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_6.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.32428563\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_6.png  processed for  Incorrect perspective rendering  with probability of, 0.3385894\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_6.png  processed for  Scale inconsistencies within single objects  with probability of, 0.0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_6.png  processed for  Spatial relationship errors  with probability of, 0.048178934\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_6.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_6.png  processed for  Depth perception anomalies  with probability of, 0.6043261\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9923\nMean value: 0.3921\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_3.png  processed for  Incorrect reflection mapping  with probability of, 0.21772125\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_3.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_3.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.632673\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_3.png  processed for  Dental anomalies in mammals  with probability of, 0.15273473\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_3.png  processed for  Anatomically incorrect paw structures  with probability of, 0.061669994\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_3.png  processed for  Unrealistic eye reflections  with probability of, 0.4645131\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_3.png  processed for  Misshapen ears or appendages  with probability of, 0.4663532\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_3.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_3.png  processed for  Biological asymmetry errors  with probability of, 0.83385295\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_3.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.9404741\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_3.png  processed for  Impossible mechanical connections  with probability of, 0.47076315\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_3.png  processed for  Impossible mechanical joints  with probability of, 0.3139226\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_3.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_3.png  processed for  Incorrect wheel geometry  with probability of, 0.95130986\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_3.png  processed for  Implausible aerodynamic structures  with probability of, 0.10345429\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_3.png  processed for  Misaligned body panels  with probability of, 0.18773843\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_3.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_3.png  processed for  Anatomically impossible joint configurations  with probability of, 0.7966407\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_3.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.1072564\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_3.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.941762\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_3.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 0.848327\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_3.png  processed for  Irregular proportions in mechanical components  with probability of, 0.56826484\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_3.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.30618978\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_3.png  processed for  Incorrect perspective rendering  with probability of, 0.2737729\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_3.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_3.png  processed for  Spatial relationship errors  with probability of, 0.40959072\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_3.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_3.png  processed for  Depth perception anomalies  with probability of, 0.8387957\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.1622\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_2.png  processed for  Incorrect reflection mapping  with probability of, 0.040881604\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_2.png  processed for  Abruptly cut off objects  with probability of, 0.38362142\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_2.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.6924018\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_2.png  processed for  Dental anomalies in mammals  with probability of, 0.61835444\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_2.png  processed for  Anatomically incorrect paw structures  with probability of, 0.30515778\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_2.png  processed for  Unrealistic eye reflections  with probability of, 0.2906597\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_2.png  processed for  Misshapen ears or appendages  with probability of, 0.6600472\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_2.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_2.png  processed for  Biological asymmetry errors  with probability of, 0.86715585\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_2.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.93259573\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_2.png  processed for  Impossible mechanical connections  with probability of, 0.2865941\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_2.png  processed for  Impossible mechanical joints  with probability of, 0.6851628\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_2.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_2.png  processed for  Incorrect wheel geometry  with probability of, 1.0\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_2.png  processed for  Implausible aerodynamic structures  with probability of, 0.17783578\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_2.png  processed for  Misaligned body panels  with probability of, 0.7516916\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_2.png  processed for  Distorted window reflections  with probability of, 0.88591033\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_2.png  processed for  Anatomically impossible joint configurations  with probability of, 0.6579877\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_2.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.69869787\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_2.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.47430745\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_2.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_2.png  processed for  Irregular proportions in mechanical components  with probability of, 0.16363913\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_2.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.26584768\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_2.png  processed for  Incorrect perspective rendering  with probability of, 0.45955852\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_2.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_2.png  processed for  Spatial relationship errors  with probability of, 0.12093752\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_2.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_2.png  processed for  Depth perception anomalies  with probability of, 0.8570534\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 31.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9645\nMean value: 0.1710\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_5.png  processed for  Incorrect reflection mapping  with probability of, 0.112543546\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_5.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_5.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.9722256\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_5.png  processed for  Dental anomalies in mammals  with probability of, 0.4049022\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_5.png  processed for  Anatomically incorrect paw structures  with probability of, 0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_5.png  processed for  Unrealistic eye reflections  with probability of, 0.24920146\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_5.png  processed for  Misshapen ears or appendages  with probability of, 0.6534408\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_5.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_5.png  processed for  Biological asymmetry errors  with probability of, 0.85208756\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_5.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.8946125\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_5.png  processed for  Impossible mechanical connections  with probability of, 0.23872526\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_5.png  processed for  Impossible mechanical joints  with probability of, 0.46188518\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_5.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_5.png  processed for  Incorrect wheel geometry  with probability of, 0.99110025\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_5.png  processed for  Implausible aerodynamic structures  with probability of, 0.38354778\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_5.png  processed for  Misaligned body panels  with probability of, 0.4473428\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_5.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_5.png  processed for  Anatomically impossible joint configurations  with probability of, 0.50102186\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_5.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.5440607\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_5.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 1.0\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_5.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_5.png  processed for  Irregular proportions in mechanical components  with probability of, 0.23877168\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_5.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.61027896\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_5.png  processed for  Incorrect perspective rendering  with probability of, 0.75684154\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_5.png  processed for  Scale inconsistencies within single objects  with probability of, 0.0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_5.png  processed for  Spatial relationship errors  with probability of, 0.45639998\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_5.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_5.png  processed for  Depth perception anomalies  with probability of, 0.88093954\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0023\nMax value: 1.0000\nMean value: 0.4815\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_7.png  processed for  Incorrect reflection mapping  with probability of, 0.23143366\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_7.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_7.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.57193583\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_7.png  processed for  Dental anomalies in mammals  with probability of, 0.13941008\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_7.png  processed for  Anatomically incorrect paw structures  with probability of, 0.0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_7.png  processed for  Unrealistic eye reflections  with probability of, 0.47517878\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_7.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_7.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_7.png  processed for  Biological asymmetry errors  with probability of, 0.3848894\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_7.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.7535779\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_7.png  processed for  Impossible mechanical connections  with probability of, 0.24980156\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_7.png  processed for  Impossible mechanical joints  with probability of, 0.79079604\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_7.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_7.png  processed for  Incorrect wheel geometry  with probability of, 0.43454146\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_7.png  processed for  Implausible aerodynamic structures  with probability of, 0.12359636\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_7.png  processed for  Misaligned body panels  with probability of, 0.052880395\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_7.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_7.png  processed for  Anatomically impossible joint configurations  with probability of, 0.1285904\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_7.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.11578266\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_7.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.69468117\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_7.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_7.png  processed for  Irregular proportions in mechanical components  with probability of, 0.18978599\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_7.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.05335992\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_7.png  processed for  Incorrect perspective rendering  with probability of, 0.088148065\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_7.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_7.png  processed for  Spatial relationship errors  with probability of, 0.34840462\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_7.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_7.png  processed for  Depth perception anomalies  with probability of, 0.77158326\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 32.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2258\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_10.png  processed for  Incorrect reflection mapping  with probability of, 1.0\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_10.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_10.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 1.0\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_10.png  processed for  Dental anomalies in mammals  with probability of, 0.31926593\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_10.png  processed for  Anatomically incorrect paw structures  with probability of, 0.0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_10.png  processed for  Unrealistic eye reflections  with probability of, 0.2249463\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_10.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_10.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_10.png  processed for  Biological asymmetry errors  with probability of, 0.6422024\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_10.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.9563415\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_10.png  processed for  Impossible mechanical connections  with probability of, 0.33637568\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_10.png  processed for  Impossible mechanical joints  with probability of, 0.35425296\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_10.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_10.png  processed for  Incorrect wheel geometry  with probability of, 0.69834614\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_10.png  processed for  Implausible aerodynamic structures  with probability of, 0.35402218\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_10.png  processed for  Misaligned body panels  with probability of, 0.87220013\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_10.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_10.png  processed for  Anatomically impossible joint configurations  with probability of, 0.10962573\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_10.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.52184755\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_10.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 1.0\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_10.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_10.png  processed for  Irregular proportions in mechanical components  with probability of, 0.38864803\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_10.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.3082973\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_10.png  processed for  Incorrect perspective rendering  with probability of, 0.45671144\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_10.png  processed for  Scale inconsistencies within single objects  with probability of, 0.0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_10.png  processed for  Spatial relationship errors  with probability of, 0.17900431\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_10.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_10.png  processed for  Depth perception anomalies  with probability of, 0.5903896\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 31.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.1896\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_8.png  processed for  Incorrect reflection mapping  with probability of, -3.5790195e-05\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_8.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_8.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.74489474\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_8.png  processed for  Dental anomalies in mammals  with probability of, 0.35867646\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_8.png  processed for  Anatomically incorrect paw structures  with probability of, 0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_8.png  processed for  Unrealistic eye reflections  with probability of, 0.8008902\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_8.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_8.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_8.png  processed for  Biological asymmetry errors  with probability of, 0.67245865\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_8.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.68415713\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_8.png  processed for  Impossible mechanical connections  with probability of, 0.4672573\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_8.png  processed for  Impossible mechanical joints  with probability of, 1.0000808\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_8.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_8.png  processed for  Incorrect wheel geometry  with probability of, 0.94998574\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_8.png  processed for  Implausible aerodynamic structures  with probability of, 0.16233577\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_8.png  processed for  Misaligned body panels  with probability of, 0.42299756\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_8.png  processed for  Distorted window reflections  with probability of, 0.9300411\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_8.png  processed for  Anatomically impossible joint configurations  with probability of, 0.4099607\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_8.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.9005096\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_8.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.34360167\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_8.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_8.png  processed for  Irregular proportions in mechanical components  with probability of, 0.001691865\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_8.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.52190584\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_8.png  processed for  Incorrect perspective rendering  with probability of, 0.5701315\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_8.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_8.png  processed for  Spatial relationship errors  with probability of, 0.9838448\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_8.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_8.png  processed for  Depth perception anomalies  with probability of, 1.0000423\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 29.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9977\nMean value: 0.3279\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_4.png  processed for  Incorrect reflection mapping  with probability of, 0.10510454\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_4.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_4.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.9363378\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_4.png  processed for  Dental anomalies in mammals  with probability of, 0.40120396\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_4.png  processed for  Anatomically incorrect paw structures  with probability of, 0.0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_4.png  processed for  Unrealistic eye reflections  with probability of, 0.66175824\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_4.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_4.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_4.png  processed for  Biological asymmetry errors  with probability of, 0.73030555\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_4.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.970234\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_4.png  processed for  Impossible mechanical connections  with probability of, 0.34282875\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_4.png  processed for  Impossible mechanical joints  with probability of, 0.9929902\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_4.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_4.png  processed for  Incorrect wheel geometry  with probability of, 0.9667421\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_4.png  processed for  Implausible aerodynamic structures  with probability of, 0.1243975\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_4.png  processed for  Misaligned body panels  with probability of, 0.6564939\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_4.png  processed for  Distorted window reflections  with probability of, 1.0\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_4.png  processed for  Anatomically impossible joint configurations  with probability of, 0.36217633\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_4.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.21931416\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_4.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 1.0\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_4.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_4.png  processed for  Irregular proportions in mechanical components  with probability of, 0.6789086\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_4.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.625454\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_4.png  processed for  Incorrect perspective rendering  with probability of, 0.8315564\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_4.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_4.png  processed for  Spatial relationship errors  with probability of, 0.2960776\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_4.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_4.png  processed for  Depth perception anomalies  with probability of, 0.83501\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 32.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2523\n['Reflections that do not match', 'Reflections accurately match the surrounding', 'N/A for non-reflective scenes']\nImage_9.png  processed for  Incorrect reflection mapping  with probability of, 0.014033097\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_9.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Duplicate elements that appear faint', 'Elements are unique and do', 'Solid, non-transparent objects']\nImage_9.png  processed for  Ghosting effects: Semi-transparent duplicates of elements  with probability of, 0.55091214\n['Teeth that are shaped or', 'Teeth are correctly shaped and', 'N/A for Non-biological or abstract']\nImage_9.png  processed for  Dental anomalies in mammals  with probability of, 0.31650913\n['Paws that do not resemble', 'Paws follow the natural anatomy', 'N/A for Non-furry or non-biological']\nImage_9.png  processed for  Anatomically incorrect paw structures  with probability of, 0.0\n['overly bright, sharp, or distorted', 'Eye reflections are subtle, aligned', 'N/A for subjects without eyes']\nImage_9.png  processed for  Unrealistic eye reflections  with probability of, 0.5992512\n['Ears or appendages that are', 'Ears and appendages have natural', 'N/A for subjects without ears/appendages']\nImage_9.png  processed for  Misshapen ears or appendages  with probability of, 1.0\n['Poses that are physically impossible.', 'Poses are physically possible and', 'N/A for non-posed subjects']\nImage_9.png  processed for  Unnatural pose artifacts  with probability of, 0.0\n['Natural objects or creatures that', 'Natural objects or creatures are', 'N/A for non-biological subjects']\nImage_9.png  processed for  Biological asymmetry errors  with probability of, 0.5477062\n['Animal parts appear unrealistically distorted', 'Animal parts are proportionate and', 'N/A for scenes without animals']\nImage_9.png  processed for  Impossible foreshortening in animal bodies  with probability of, 0.79657346\n['Connections between mechanical parts that', 'Connections between mechanical parts are', 'N/A for non-mechanical subjects']\nImage_9.png  processed for  Impossible mechanical connections  with probability of, 0.23505639\n['Joints that would not work', 'Joints are realistic, with functional', 'N/A for subjects without joints']\nImage_9.png  processed for  Impossible mechanical joints  with probability of, 0.36745143\n['Structures that defy physical laws', 'Structures obey physical laws, maintaining', 'Real-world architecture or natural objects']\nImage_9.png  processed for  Physically impossible structural elements  with probability of, 0.0\n['Wheels that are misshapen or', 'Wheels are correctly shaped, aligned,', 'N/A for scenes without wheels']\nImage_9.png  processed for  Incorrect wheel geometry  with probability of, 0.8327658\n['Structures may appear bulky, poorly', 'Structures are streamlined and aerodynamically', 'N/A for non-aerodynamic subjects']\nImage_9.png  processed for  Implausible aerodynamic structures  with probability of, 0.21249382\n[\"Parts of an object's exterior,\", 'Panels are properly aligned with', 'N/A for non-vehicular subjects']\nImage_9.png  processed for  Misaligned body panels  with probability of, 0.74121445\n['Distorted window reflections occur when', 'Window reflections are natural, clear,', 'N/A for scenes without windows']\nImage_9.png  processed for  Distorted window reflections  with probability of, 0.62514246\n['Joints in animals or humans', 'Joints bend naturally and realistically', 'N/A for subjects without joints']\nImage_9.png  processed for  Anatomically impossible joint configurations  with probability of, 0.12589768\n[\"Objects don't obey standard 3D\", 'Objects follow standard 3D rules', 'Natural organic objects like animals']\nImage_9.png  processed for  Non-manifold geometries in rigid structures  with probability of, 0.3588827\n['Objects that should be symmetric', 'Natural symmetry is maintained throughout', 'Abstract art or random objects']\nImage_9.png  processed for  Asymmetric features in naturally symmetric objects  with probability of, 0.29139605\n['Animal faces where both sides', 'Animal faces show proper bilateral', 'Non-organic objects like mechanical or']\nImage_9.png  processed for  Misaligned bilateral elements in animal faces  with probability of, 1.0\n['Mechanical parts that are oddly', 'All mechanical components maintain correct', 'Natural objects or creatures']\nImage_9.png  processed for  Irregular proportions in mechanical components  with probability of, 0.27840835\n['Mechanical parts that are not', 'Mechanical parts are sized proportionally', 'N/A for non-mechanical subjects']\nImage_9.png  processed for  Inconsistent scale of mechanical parts  with probability of, 0.18555498\n['Proportions, angles, or depth of', 'Objects are correctly aligned with', 'Simple 2D representations']\nImage_9.png  processed for  Incorrect perspective rendering  with probability of, 0.4465427\n['Different parts of the same', 'All parts of the object', 'Static, non-3D images']\nImage_9.png  processed for  Scale inconsistencies within single objects  with probability of, 0\n['Objects placed incorrectly relative to', 'Objects are correctly placed with', 'Flat or 2D images']\nImage_9.png  processed for  Spatial relationship errors  with probability of, 0.2135306\n['objects of the same type', 'Objects of the same type', 'Proportionally accurate models']\nImage_9.png  processed for  Scale inconsistencies within the same object class  with probability of, 1.0\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_9.png  processed for  Depth perception anomalies  with probability of, 0.78288645\n{'Image_1.png': ['Incorrect reflection mapping', 'Impossible foreshortening in animal bodies', 'Impossible mechanical connections', 'Distorted window reflections', 'Anatomically impossible joint configurations', 'Scale inconsistencies within the same object class'], 'Image_6.png': ['Unrealistic eye reflections', 'Misshapen ears or appendages', 'Impossible foreshortening in animal bodies', 'Impossible mechanical joints', 'Incorrect wheel geometry', 'Misaligned body panels', 'Distorted window reflections', 'Non-manifold geometries in rigid structures', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class'], 'Image_3.png': ['Biological asymmetry errors', 'Impossible foreshortening in animal bodies', 'Incorrect wheel geometry', 'Distorted window reflections', 'Anatomically impossible joint configurations', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_2.png': ['Biological asymmetry errors', 'Impossible foreshortening in animal bodies', 'Incorrect wheel geometry', 'Misaligned body panels', 'Distorted window reflections', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_5.png': ['Ghosting effects: Semi-transparent duplicates of elements', 'Biological asymmetry errors', 'Impossible foreshortening in animal bodies', 'Incorrect wheel geometry', 'Distorted window reflections', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Incorrect perspective rendering', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_7.png': ['Misshapen ears or appendages', 'Impossible foreshortening in animal bodies', 'Impossible mechanical joints', 'Distorted window reflections', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_10.png': ['Incorrect reflection mapping', 'Ghosting effects: Semi-transparent duplicates of elements', 'Misshapen ears or appendages', 'Impossible foreshortening in animal bodies', 'Misaligned body panels', 'Distorted window reflections', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class'], 'Image_8.png': ['Ghosting effects: Semi-transparent duplicates of elements', 'Unrealistic eye reflections', 'Misshapen ears or appendages', 'Impossible mechanical joints', 'Incorrect wheel geometry', 'Distorted window reflections', 'Non-manifold geometries in rigid structures', 'Misaligned bilateral elements in animal faces', 'Spatial relationship errors', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_4.png': ['Ghosting effects: Semi-transparent duplicates of elements', 'Misshapen ears or appendages', 'Biological asymmetry errors', 'Impossible foreshortening in animal bodies', 'Impossible mechanical joints', 'Incorrect wheel geometry', 'Distorted window reflections', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Incorrect perspective rendering', 'Scale inconsistencies within the same object class', 'Depth perception anomalies'], 'Image_9.png': ['Misshapen ears or appendages', 'Impossible foreshortening in animal bodies', 'Incorrect wheel geometry', 'Misaligned body panels', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class', 'Depth perception anomalies']}\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# process_img_final_with_downsize_to_32(\"/kaggle/input/pegasus/Screenshot 2024-11-24 161819.png\")\n# # process_img_final_already_32(\"/kaggle/input/cifake-test/1019 (2).jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T09:59:11.655379Z","iopub.execute_input":"2024-11-28T09:59:11.656270Z","iopub.status.idle":"2024-11-28T09:59:13.122849Z","shell.execute_reply.started":"2024-11-28T09:59:11.656236Z","shell.execute_reply":"2024-11-28T09:59:13.121966Z"}},"outputs":[{"name":"stdout","text":"(48, 48)\n(768, 768)\n(768, 768)\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"print(result[\"Image_6.png\"])\nprint(image_artifacts['Image_6.png'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:59:17.782912Z","iopub.execute_input":"2024-11-28T12:59:17.783302Z","iopub.status.idle":"2024-11-28T12:59:17.788366Z","shell.execute_reply.started":"2024-11-28T12:59:17.783271Z","shell.execute_reply":"2024-11-28T12:59:17.787284Z"}},"outputs":[{"name":"stdout","text":"['Unrealistic eye reflections', 'Misshapen ears or appendages', 'Impossible foreshortening in animal bodies', 'Impossible mechanical joints', 'Incorrect wheel geometry', 'Misaligned body panels', 'Distorted window reflections', 'Non-manifold geometries in rigid structures', 'Asymmetric features in naturally symmetric objects', 'Misaligned bilateral elements in animal faces', 'Scale inconsistencies within the same object class']\n['Inconsistent scale of mechanical parts']\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"def find_artifacts_in_image_32(folder_path, threshold = 0.5):\n    non_sr_artifacts = [\n        \"Improper fur direction flows\",\n        \"Incorrect skin tones\",\n        \"Inconsistent object boundaries\",\n        \"Blurred boundaries in fine details\",\n        \"Over-sharpening artifacts\",\n        \"Excessive sharpness in certain image regions\",\n        \"Aliasing along high-contrast edges\",\n        \"Jagged edges in curved structures\",\n        \"Fake depth of field\",\n        \"Artificial depth of field in object presentation\",\n        \"Discontinuous surfaces\",\n        \"Unnaturally glossy surfaces\",\n        \"Metallic surface artifacts\",\n        \"Texture bleeding between adjacent regions\",\n        \"Texture repetition patterns\",\n        \"Over-smoothing of natural textures\",\n        \"Regular grid-like artifacts in textures\",\n        \"Artificial noise patterns in uniform surfaces\",\n        \"Random noise patterns in detailed areas\",\n        \"Repeated element patterns\",\n        \"Systematic color distribution anomalies\",\n        \"Unnatural color transitions\",\n        \"Color coherence breaks\",\n        \"Frequency domain signatures\",\n        \"Artificial smoothness\",\n        \"Cinematization effects\",\n        \"Movie-poster-like composition of ordinary scenes\",\n        \"Exaggerated characteristic features\",\n        \"Synthetic material appearance\",\n        \"Floating or disconnected components\",\n        \"Inconsistent material properties\",\n        \"Depth perception anomalies\",\n        \"Loss of fine detail in complex structures\",\n        \"Resolution inconsistencies within regions\",\n        \"Abruptly cut off objects\",\n        \"Unrealistic specular highlights\",\n    ]\n\n\n    tuple_desc = pd.read_csv('/kaggle/input/simplified-tuple-artifact/simplified_artifact_descriptions.csv')\n    # filter_artifacts(folder_path)\n    # filter = Filter()\n    # filter.filter_artifacts(folder_path)\n    result = {}\n    artifact_detector = Final()\n    for filename in os.listdir(folder_path):\n        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\")):\n            # Read and preprocess the image\n            image_path = os.path.join(folder_path, filename)\n            # artifacts = extract_probable_artifacts_from_JSON(filename)\n            artifacts_present = []\n            setup_image(image_path)\n            for artifact in non_sr_artifacts:\n                # description = tuple_desc['Artifact'].loc(tuple_desc) #write code to get list of artifact 3 tuple\n                row = tuple_desc[tuple_desc['Artifact'] == artifact]\n                if not (row.empty): \n                    description = row.iloc[0, 1:].tolist()\n                else:\n                    continue\n                print(description)\n                \n                score = artifact_detector.final_img_process(description)\n                if score>threshold: \n                    artifacts_present.append(artifact)\n                print(filename, \" processed for \", artifact, \" with probability of,\", score)\n                \n            result[filename] = artifacts_present\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:12:42.612417Z","iopub.execute_input":"2024-11-28T13:12:42.613402Z","iopub.status.idle":"2024-11-28T13:12:42.626532Z","shell.execute_reply.started":"2024-11-28T13:12:42.613352Z","shell.execute_reply":"2024-11-28T13:12:42.625532Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"image_artifacts = {\n    \"Image_1.png\": [\n        \"Biological asymmetry error\",\n        \"Anatomically impossible joint configurations\",\n        \"Scale inconsistencies within single objects\",\n        \"Unnaturally glossy surfaces\",\n        \"Unnatural color transitions\",\n        \"Cinematization effects\",\n        \"Over smoothing of natural textures\",\n    ],\n    \"Image_2.png\": [\n        \"Unnatural glossy surfaces\",\n        \"Excessive sharpness in certain image regions\",\n        \"Color coherence breaks\",\n    ],\n    \"Image_3.png\": [\n        \"Missshapen ears or appendages\",\n        \"Anatomically incorrect paw structures\",\n        \"Dental anomalies in animals\",\n        \"Over smoothing of natural textures\",\n    ],\n    \"Image_4.png\": [\n        \"Abruptly cut off objects\",\n        \"Biological asymmetry errors\",\n        \"Asymmetric features in naturally symmetric objects\",\n        \"Scale inconsistencies within single objects\",\n        \"Impossible foreshortening in animal bodies\",\n    ],\n    \"Image_5.png\": [\n        \"Anatomically impossible joint configurations\",\n        \"Systematic color distribution anomalies\",\n        \"Artificial smoothness\",\n    ],\n    \"Image_6.png\": [\n        \"Glow or light bleed around object boundaries\",\n        \"Inconsistent scale of mechanical parts\",\n    ],\n    \"Image_7.png\": [\n        \"Dramatic lighting that defies natural surfaces\",\n        \"Metallic surface artifacts\",\n        \"Multiple light source conflicts\",\n        \"Unnatural color transitions\",\n        \"Unrealistic specular highlights\",\n    ],\n    \"Image_8.png\": [\n        \"Inconsistent shadow directions\",\n        \"Impossible mechanical connections\",\n        \"Non-manifold geometries in rigid structures\",\n        \"Implausible aerodynamic structures\",\n    ],\n    \"Image_9.png\": [\n        \"Incorrect reflection mapping\",\n        \"Scale inconsistencies within single objects\",\n        \"Blurred boundaries in fine details\",\n    ],\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:25:44.569490Z","iopub.execute_input":"2024-11-28T13:25:44.569839Z","iopub.status.idle":"2024-11-28T13:25:44.576016Z","shell.execute_reply.started":"2024-11-28T13:25:44.569804Z","shell.execute_reply":"2024-11-28T13:25:44.575143Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def calculate_iou(dict1, dict2):\n    iou_scores = {}\n    \n    for image_name in dict1:\n        if image_name in dict2:\n            # Get the sets of artifacts\n            artifacts1 = set(dict1[image_name])\n            artifacts2 = set(dict2[image_name])\n            \n            # Calculate intersection and union\n            intersection = artifacts1 & artifacts2\n            union = artifacts1 | artifacts2\n            \n            # Calculate IoU\n            iou = len(intersection) / len(union) if union else 0\n            iou_scores[image_name] = iou\n    \n    return iou_scores\n\n# Example usage\niou_scores = calculate_iou(image_artifacts, result_32)\nprint(iou_scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:25:53.424459Z","iopub.execute_input":"2024-11-28T13:25:53.425143Z","iopub.status.idle":"2024-11-28T13:25:53.431128Z","shell.execute_reply.started":"2024-11-28T13:25:53.425109Z","shell.execute_reply":"2024-11-28T13:25:53.430162Z"}},"outputs":[{"name":"stdout","text":"{'Image_1.png': 0.05263157894736842, 'Image_2.png': 0.09090909090909091, 'Image_3.png': 0.0, 'Image_4.png': 0.0, 'Image_5.png': 0.047619047619047616, 'Image_6.png': 0.0, 'Image_7.png': 0.125, 'Image_8.png': 0.0, 'Image_9.png': 0.0}\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"result_32 = find_artifacts_in_image_32(\"/kaggle/input/manually-labelled-artifacts\", 0.9)\nprint(result_32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:28:36.067121Z","iopub.execute_input":"2024-11-28T13:28:36.067457Z","iopub.status.idle":"2024-11-28T13:36:58.749047Z","shell.execute_reply.started":"2024-11-28T13:28:36.067428Z","shell.execute_reply":"2024-11-28T13:36:58.748188Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n/tmp/ipykernel_30/3602279645.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\nGenerating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 28.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0091\nMax value: 0.9982\nMean value: 0.2934\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_1.png  processed for  Improper fur direction flows  with probability of, 0.97259974\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_1.png  processed for  Inconsistent object boundaries  with probability of, 0.96396244\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_1.png  processed for  Blurred boundaries in fine details  with probability of, 0.00353237\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_1.png  processed for  Over-sharpening artifacts  with probability of, 0.9012657\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_1.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.4812591\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_1.png  processed for  Aliasing along high-contrast edges  with probability of, 0.0\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_1.png  processed for  Jagged edges in curved structures  with probability of, 0.9074682\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_1.png  processed for  Fake depth of field  with probability of, 0.15605195\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_1.png  processed for  Artificial depth of field in object presentation  with probability of, 1.0\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_1.png  processed for  Discontinuous surfaces  with probability of, 0.9039287\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_1.png  processed for  Unnaturally glossy surfaces  with probability of, 0.99941325\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_1.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_1.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.01068904\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_1.png  processed for  Texture repetition patterns  with probability of, 0.4675797\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_1.png  processed for  Over-smoothing of natural textures  with probability of, 1.0\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_1.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_1.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.83665794\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_1.png  processed for  Random noise patterns in detailed areas  with probability of, 1.0\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_1.png  processed for  Repeated element patterns  with probability of, 0.5753067\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_1.png  processed for  Systematic color distribution anomalies  with probability of, 0.004098687\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_1.png  processed for  Unnatural color transitions  with probability of, 0.5901199\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_1.png  processed for  Color coherence breaks  with probability of, 0.6479735\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_1.png  processed for  Frequency domain signatures  with probability of, 0.28178424\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_1.png  processed for  Artificial smoothness  with probability of, 1.0\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_1.png  processed for  Exaggerated characteristic features  with probability of, 0.5064797\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_1.png  processed for  Synthetic material appearance  with probability of, 0.58367014\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_1.png  processed for  Floating or disconnected components  with probability of, 0.50450015\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_1.png  processed for  Inconsistent material properties  with probability of, 0.016621854\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_1.png  processed for  Depth perception anomalies  with probability of, 0.60590553\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_1.png  processed for  Loss of fine detail in complex structures  with probability of, 0.15929787\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_1.png  processed for  Resolution inconsistencies within regions  with probability of, 0.0\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_1.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_1.png  processed for  Unrealistic specular highlights  with probability of, 0.011348211\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2570\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_6.png  processed for  Improper fur direction flows  with probability of, 0.29831597\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_6.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_6.png  processed for  Blurred boundaries in fine details  with probability of, 0.122857295\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_6.png  processed for  Over-sharpening artifacts  with probability of, 1.0\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_6.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.7599852\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_6.png  processed for  Aliasing along high-contrast edges  with probability of, 0.44397947\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_6.png  processed for  Jagged edges in curved structures  with probability of, 0.5849549\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_6.png  processed for  Fake depth of field  with probability of, 0.38700372\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_6.png  processed for  Artificial depth of field in object presentation  with probability of, 0.39335433\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_6.png  processed for  Discontinuous surfaces  with probability of, 0.995033\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_6.png  processed for  Unnaturally glossy surfaces  with probability of, 1.0\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_6.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_6.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.15137348\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_6.png  processed for  Texture repetition patterns  with probability of, 0.7544894\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_6.png  processed for  Over-smoothing of natural textures  with probability of, 1.0\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_6.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_6.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.49526504\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_6.png  processed for  Random noise patterns in detailed areas  with probability of, 0.6384928\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_6.png  processed for  Repeated element patterns  with probability of, 0.008901178\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_6.png  processed for  Systematic color distribution anomalies  with probability of, 0.069549106\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_6.png  processed for  Unnatural color transitions  with probability of, 0.56844825\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_6.png  processed for  Color coherence breaks  with probability of, 0.98364747\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_6.png  processed for  Frequency domain signatures  with probability of, 0.17239036\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_6.png  processed for  Artificial smoothness  with probability of, 0.46451306\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_6.png  processed for  Exaggerated characteristic features  with probability of, 0.56089056\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_6.png  processed for  Synthetic material appearance  with probability of, 0.01842957\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_6.png  processed for  Floating or disconnected components  with probability of, 0.8822777\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_6.png  processed for  Inconsistent material properties  with probability of, 0.2026796\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_6.png  processed for  Depth perception anomalies  with probability of, 0.6825051\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_6.png  processed for  Loss of fine detail in complex structures  with probability of, 0.02854417\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_6.png  processed for  Resolution inconsistencies within regions  with probability of, 0.0\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_6.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_6.png  processed for  Unrealistic specular highlights  with probability of, 0.008953159\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 29.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9923\nMean value: 0.3921\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_3.png  processed for  Improper fur direction flows  with probability of, 0.7307074\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_3.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_3.png  processed for  Blurred boundaries in fine details  with probability of, 0.045492258\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_3.png  processed for  Over-sharpening artifacts  with probability of, 0.83822954\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_3.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.17861144\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_3.png  processed for  Aliasing along high-contrast edges  with probability of, 1.0\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_3.png  processed for  Jagged edges in curved structures  with probability of, 0.78708345\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_3.png  processed for  Fake depth of field  with probability of, 0.122716025\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_3.png  processed for  Artificial depth of field in object presentation  with probability of, 0.46291164\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_3.png  processed for  Discontinuous surfaces  with probability of, 0.61557746\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_3.png  processed for  Unnaturally glossy surfaces  with probability of, 0.7278702\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_3.png  processed for  Metallic surface artifacts  with probability of, 0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_3.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.044546586\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_3.png  processed for  Texture repetition patterns  with probability of, 0.40556216\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_3.png  processed for  Over-smoothing of natural textures  with probability of, 0.41378075\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_3.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_3.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.97355235\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_3.png  processed for  Random noise patterns in detailed areas  with probability of, 0.7489577\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_3.png  processed for  Repeated element patterns  with probability of, 0.76973236\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_3.png  processed for  Systematic color distribution anomalies  with probability of, 0.052649196\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_3.png  processed for  Unnatural color transitions  with probability of, 0.7159385\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_3.png  processed for  Color coherence breaks  with probability of, 0.57178056\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_3.png  processed for  Frequency domain signatures  with probability of, 0.021409176\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_3.png  processed for  Artificial smoothness  with probability of, 0.56799984\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_3.png  processed for  Exaggerated characteristic features  with probability of, 0.4354512\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_3.png  processed for  Synthetic material appearance  with probability of, 0.18600976\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_3.png  processed for  Floating or disconnected components  with probability of, 0.73147976\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_3.png  processed for  Inconsistent material properties  with probability of, 0.052656345\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_3.png  processed for  Depth perception anomalies  with probability of, 0.7975991\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_3.png  processed for  Loss of fine detail in complex structures  with probability of, 0.027761305\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_3.png  processed for  Resolution inconsistencies within regions  with probability of, 0.0\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_3.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_3.png  processed for  Unrealistic specular highlights  with probability of, 0.0105562685\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 31.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.1622\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_2.png  processed for  Improper fur direction flows  with probability of, 0.15591703\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_2.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_2.png  processed for  Blurred boundaries in fine details  with probability of, 0.099534936\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_2.png  processed for  Over-sharpening artifacts  with probability of, 0.7909428\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_2.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.7211015\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_2.png  processed for  Aliasing along high-contrast edges  with probability of, 1.0\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_2.png  processed for  Jagged edges in curved structures  with probability of, 0.3253503\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_2.png  processed for  Fake depth of field  with probability of, 0.60044646\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_2.png  processed for  Artificial depth of field in object presentation  with probability of, 0.42538753\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_2.png  processed for  Discontinuous surfaces  with probability of, 0.8262927\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_2.png  processed for  Unnaturally glossy surfaces  with probability of, 0.61328036\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_2.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_2.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.17452104\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_2.png  processed for  Texture repetition patterns  with probability of, 0.6871933\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_2.png  processed for  Over-smoothing of natural textures  with probability of, 0.70944965\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_2.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_2.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.6095208\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_2.png  processed for  Random noise patterns in detailed areas  with probability of, 0.85090935\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_2.png  processed for  Repeated element patterns  with probability of, 0.1388512\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_2.png  processed for  Systematic color distribution anomalies  with probability of, 0.109276034\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_2.png  processed for  Unnatural color transitions  with probability of, 0.2533714\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_2.png  processed for  Color coherence breaks  with probability of, 0.9904804\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_2.png  processed for  Frequency domain signatures  with probability of, 0.43761823\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_2.png  processed for  Artificial smoothness  with probability of, 0.6234655\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_2.png  processed for  Exaggerated characteristic features  with probability of, 0.9159165\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_2.png  processed for  Synthetic material appearance  with probability of, 0.26536077\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_2.png  processed for  Floating or disconnected components  with probability of, 0.8373194\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_2.png  processed for  Inconsistent material properties  with probability of, 0.2728163\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_2.png  processed for  Depth perception anomalies  with probability of, 0.90473187\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_2.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_2.png  processed for  Resolution inconsistencies within regions  with probability of, 0.31031194\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_2.png  processed for  Abruptly cut off objects  with probability of, 0.38774928\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_2.png  processed for  Unrealistic specular highlights  with probability of, 0.0\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 29.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9645\nMean value: 0.1710\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_5.png  processed for  Improper fur direction flows  with probability of, 0.4025282\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_5.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_5.png  processed for  Blurred boundaries in fine details  with probability of, 0.12787387\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_5.png  processed for  Over-sharpening artifacts  with probability of, 0.8560775\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_5.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.85166574\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_5.png  processed for  Aliasing along high-contrast edges  with probability of, 0.20726098\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_5.png  processed for  Jagged edges in curved structures  with probability of, 0.44950172\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_5.png  processed for  Fake depth of field  with probability of, 0.17058076\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_5.png  processed for  Artificial depth of field in object presentation  with probability of, 0.74979186\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_5.png  processed for  Discontinuous surfaces  with probability of, 1.0\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_5.png  processed for  Unnaturally glossy surfaces  with probability of, 1.0\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_5.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_5.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.074790016\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_5.png  processed for  Texture repetition patterns  with probability of, 0.95518154\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_5.png  processed for  Over-smoothing of natural textures  with probability of, 1.0\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_5.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_5.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.83791715\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_5.png  processed for  Random noise patterns in detailed areas  with probability of, 1.0\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_5.png  processed for  Repeated element patterns  with probability of, 0.6585182\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_5.png  processed for  Systematic color distribution anomalies  with probability of, 0.03935092\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_5.png  processed for  Unnatural color transitions  with probability of, 0.86328375\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_5.png  processed for  Color coherence breaks  with probability of, 0.9893077\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_5.png  processed for  Frequency domain signatures  with probability of, 0.36862692\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_5.png  processed for  Artificial smoothness  with probability of, 0.8734594\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_5.png  processed for  Exaggerated characteristic features  with probability of, 0.86183226\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_5.png  processed for  Synthetic material appearance  with probability of, 0.26194203\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_5.png  processed for  Floating or disconnected components  with probability of, 0.91502273\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_5.png  processed for  Inconsistent material properties  with probability of, 0.10094187\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_5.png  processed for  Depth perception anomalies  with probability of, 0.84584874\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_5.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_5.png  processed for  Resolution inconsistencies within regions  with probability of, 0.43148023\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_5.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_5.png  processed for  Unrealistic specular highlights  with probability of, 0.31824923\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0023\nMax value: 1.0000\nMean value: 0.4815\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_7.png  processed for  Improper fur direction flows  with probability of, 0.11443758\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_7.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_7.png  processed for  Blurred boundaries in fine details  with probability of, 0.0\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_7.png  processed for  Over-sharpening artifacts  with probability of, 0.9625127\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_7.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.3393472\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_7.png  processed for  Aliasing along high-contrast edges  with probability of, 0.65768504\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_7.png  processed for  Jagged edges in curved structures  with probability of, 0.48212036\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_7.png  processed for  Fake depth of field  with probability of, 0.2888345\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_7.png  processed for  Artificial depth of field in object presentation  with probability of, 0.5088017\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_7.png  processed for  Discontinuous surfaces  with probability of, 0.4811868\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_7.png  processed for  Unnaturally glossy surfaces  with probability of, 0.75\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_7.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_7.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.03797915\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_7.png  processed for  Texture repetition patterns  with probability of, 0.80519706\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_7.png  processed for  Over-smoothing of natural textures  with probability of, 1.0\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_7.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_7.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.48705786\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_7.png  processed for  Random noise patterns in detailed areas  with probability of, 0.7479806\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_7.png  processed for  Repeated element patterns  with probability of, 1.0\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_7.png  processed for  Systematic color distribution anomalies  with probability of, 0.03484196\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_7.png  processed for  Unnatural color transitions  with probability of, 0.75597\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_7.png  processed for  Color coherence breaks  with probability of, 0.77535915\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_7.png  processed for  Frequency domain signatures  with probability of, 0.0\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_7.png  processed for  Artificial smoothness  with probability of, 0.6187565\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_7.png  processed for  Exaggerated characteristic features  with probability of, 0.53955466\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_7.png  processed for  Synthetic material appearance  with probability of, 0.75242245\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_7.png  processed for  Floating or disconnected components  with probability of, 0.5768519\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_7.png  processed for  Inconsistent material properties  with probability of, 0.05420378\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_7.png  processed for  Depth perception anomalies  with probability of, 0.8222508\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_7.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_7.png  processed for  Resolution inconsistencies within regions  with probability of, 0.10221777\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_7.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_7.png  processed for  Unrealistic specular highlights  with probability of, 0.28741038\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2258\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_10.png  processed for  Improper fur direction flows  with probability of, 1.0\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_10.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_10.png  processed for  Blurred boundaries in fine details  with probability of, 0.040940855\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_10.png  processed for  Over-sharpening artifacts  with probability of, 0.9444406\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_10.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.9128537\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_10.png  processed for  Aliasing along high-contrast edges  with probability of, 0.91827226\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_10.png  processed for  Jagged edges in curved structures  with probability of, 0.32309768\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_10.png  processed for  Fake depth of field  with probability of, 0.38879114\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_10.png  processed for  Artificial depth of field in object presentation  with probability of, 0.84077936\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_10.png  processed for  Discontinuous surfaces  with probability of, 0.9650752\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_10.png  processed for  Unnaturally glossy surfaces  with probability of, 0.87298614\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_10.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_10.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.20521213\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_10.png  processed for  Texture repetition patterns  with probability of, 1.0\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_10.png  processed for  Over-smoothing of natural textures  with probability of, 1.0\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_10.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_10.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.5450781\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_10.png  processed for  Random noise patterns in detailed areas  with probability of, 1.0\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_10.png  processed for  Repeated element patterns  with probability of, 1.0\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_10.png  processed for  Systematic color distribution anomalies  with probability of, 0.14020412\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_10.png  processed for  Unnatural color transitions  with probability of, 0.48387983\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_10.png  processed for  Color coherence breaks  with probability of, 0.99429345\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_10.png  processed for  Frequency domain signatures  with probability of, 0.006679772\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_10.png  processed for  Artificial smoothness  with probability of, 1.0\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_10.png  processed for  Exaggerated characteristic features  with probability of, 0.42748147\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_10.png  processed for  Synthetic material appearance  with probability of, 0.04048895\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_10.png  processed for  Floating or disconnected components  with probability of, 0.7745325\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_10.png  processed for  Inconsistent material properties  with probability of, 0.30316037\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_10.png  processed for  Depth perception anomalies  with probability of, 0.5984094\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_10.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_10.png  processed for  Resolution inconsistencies within regions  with probability of, 0.0\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_10.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_10.png  processed for  Unrealistic specular highlights  with probability of, 0.41008484\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 30.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.1896\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_8.png  processed for  Improper fur direction flows  with probability of, 0.2509062\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_8.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_8.png  processed for  Blurred boundaries in fine details  with probability of, 0.11168563\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_8.png  processed for  Over-sharpening artifacts  with probability of, 1.0\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_8.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.6526463\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_8.png  processed for  Aliasing along high-contrast edges  with probability of, 0.0\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_8.png  processed for  Jagged edges in curved structures  with probability of, 0.2437392\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_8.png  processed for  Fake depth of field  with probability of, 0.0039766785\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_8.png  processed for  Artificial depth of field in object presentation  with probability of, 0.37522107\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_8.png  processed for  Discontinuous surfaces  with probability of, 0.58849454\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_8.png  processed for  Unnaturally glossy surfaces  with probability of, 0.4937572\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_8.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_8.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.1398689\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_8.png  processed for  Texture repetition patterns  with probability of, 1.0\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_8.png  processed for  Over-smoothing of natural textures  with probability of, 0.6079261\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_8.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_8.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.74489474\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_8.png  processed for  Random noise patterns in detailed areas  with probability of, 0.75000006\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_8.png  processed for  Repeated element patterns  with probability of, 0.99218726\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_8.png  processed for  Systematic color distribution anomalies  with probability of, 0.36431578\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_8.png  processed for  Unnatural color transitions  with probability of, 0.28554615\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_8.png  processed for  Color coherence breaks  with probability of, 0.99963325\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_8.png  processed for  Frequency domain signatures  with probability of, 0.18740958\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_8.png  processed for  Artificial smoothness  with probability of, 0.74768966\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_8.png  processed for  Exaggerated characteristic features  with probability of, 0.8298634\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_8.png  processed for  Synthetic material appearance  with probability of, 0.082796626\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_8.png  processed for  Floating or disconnected components  with probability of, 0.9614217\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_8.png  processed for  Inconsistent material properties  with probability of, 0.2125864\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_8.png  processed for  Depth perception anomalies  with probability of, 1.0000248\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_8.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_8.png  processed for  Resolution inconsistencies within regions  with probability of, 0.67514986\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_8.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_8.png  processed for  Unrealistic specular highlights  with probability of, 0.00697209\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 32.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 0.9977\nMean value: 0.3279\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_4.png  processed for  Improper fur direction flows  with probability of, 0.28718692\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_4.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_4.png  processed for  Blurred boundaries in fine details  with probability of, 0.44732067\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_4.png  processed for  Over-sharpening artifacts  with probability of, 0.7116731\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_4.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.39617252\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_4.png  processed for  Aliasing along high-contrast edges  with probability of, 0.24171384\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_4.png  processed for  Jagged edges in curved structures  with probability of, 0.37389877\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_4.png  processed for  Fake depth of field  with probability of, 0.08634919\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_4.png  processed for  Artificial depth of field in object presentation  with probability of, 0.5262158\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_4.png  processed for  Discontinuous surfaces  with probability of, 1.0\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_4.png  processed for  Unnaturally glossy surfaces  with probability of, 1.0\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_4.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_4.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.2933298\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_4.png  processed for  Texture repetition patterns  with probability of, 0.86079127\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_4.png  processed for  Over-smoothing of natural textures  with probability of, 0.6189751\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_4.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_4.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.8286871\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_4.png  processed for  Random noise patterns in detailed areas  with probability of, 0.75\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_4.png  processed for  Repeated element patterns  with probability of, 0.49690723\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_4.png  processed for  Systematic color distribution anomalies  with probability of, 0.09767065\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_4.png  processed for  Unnatural color transitions  with probability of, 0.31213996\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_4.png  processed for  Color coherence breaks  with probability of, 0.7044434\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_4.png  processed for  Frequency domain signatures  with probability of, 0.5719635\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_4.png  processed for  Artificial smoothness  with probability of, 0.5361117\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_4.png  processed for  Exaggerated characteristic features  with probability of, 0.6591928\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_4.png  processed for  Synthetic material appearance  with probability of, 0.13207841\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_4.png  processed for  Floating or disconnected components  with probability of, 0.6358817\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_4.png  processed for  Inconsistent material properties  with probability of, 0.15150042\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_4.png  processed for  Depth perception anomalies  with probability of, 0.8215836\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_4.png  processed for  Loss of fine detail in complex structures  with probability of, 0.0\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_4.png  processed for  Resolution inconsistencies within regions  with probability of, 0.015021053\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_4.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_4.png  processed for  Unrealistic specular highlights  with probability of, 0.43282104\n","output_type":"stream"},{"name":"stderr","text":"Generating Grad-CAM visualizations: 100%|██████████| 1/1 [00:00<00:00, 29.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Intensity Matrix Shape: (32, 32)\nMin value: 0.0000\nMax value: 1.0000\nMean value: 0.2523\n['Fur that grows in unrealistic', 'Fur grows naturally with proper', 'N/A for Non-furry objects']\nImage_9.png  processed for  Improper fur direction flows  with probability of, 0.28664318\n['Edges of objects are unclear,', 'Objects have clear and well-defined', 'Flat 2D images, simple backgrounds']\nImage_9.png  processed for  Inconsistent object boundaries  with probability of, 1.0\n['Details appear soft or smudged.', 'Details are sharp, clear, and', 'Simple, large objects']\nImage_9.png  processed for  Blurred boundaries in fine details  with probability of, 0.18258812\n['Edges appear unnaturally sharp.', 'Edges are naturally smooth and', 'Soft or out-of-focus images']\nImage_9.png  processed for  Over-sharpening artifacts  with probability of, 0.8776951\n['Some parts of the image', 'Sharpness is consistent and realistic', 'Soft, blurred regions']\nImage_9.png  processed for  Excessive sharpness in certain image regions  with probability of, 0.21786696\n['Visible \"staircase\" or jagged pattern', 'Transitions between light and dark', 'Blurred or soft-edged images']\nImage_9.png  processed for  Aliasing along high-contrast edges  with probability of, 0.83266854\n['smooth, naturally flowing curves like', 'Curves and organic shapes are', 'Straight or geometric objects']\nImage_9.png  processed for  Jagged edges in curved structures  with probability of, 0.6761122\n['The transition between sharp and', 'Transitions between sharp and blurry', 'photographs or non-blurry scenes']\nImage_9.png  processed for  Fake depth of field  with probability of, 0.11877142\n['Blur effects added unnaturally for', 'Blur effects are applied naturally,', 'Regular 2D or non-enhanced images']\nImage_9.png  processed for  Artificial depth of field in object presentation  with probability of, 0.4050788\n['Surfaces that appear broken(fragmented) or', 'Surfaces have clear and well-defined', 'Simple or flat textures']\nImage_9.png  processed for  Discontinuous surfaces  with probability of, 0.6191706\n['Surfaces appear overly shiny and', 'Surfaces maintain natural shine, consistent', 'Matte or rough objects']\nImage_9.png  processed for  Unnaturally glossy surfaces  with probability of, 0.615412\n['surfaces intended to resemble metal', 'Surfaces intended to resemble metal', 'N/A for Non-metallic, organic surfaces']\nImage_9.png  processed for  Metallic surface artifacts  with probability of, 1.0\n['Textures that spill over to', 'Textures are properly confined to', 'Simple color backgrounds or low-detail']\nImage_9.png  processed for  Texture bleeding between adjacent regions  with probability of, 0.076118186\n['Repeating texture patterns that look', 'Textures show natural variation without', 'Organic or non-repetitive objects']\nImage_9.png  processed for  Texture repetition patterns  with probability of, 0.6440524\n['Details in textures are overly', 'Natural textures maintain appropriate detail', 'Artificial objects with hard surfaces']\nImage_9.png  processed for  Over-smoothing of natural textures  with probability of, 0.5284646\n['Repetitive, grid-patterned distortions appear across', 'Surfaces are free from repetitive', 'Smooth surfaces or organic textures']\nImage_9.png  processed for  Regular grid-like artifacts in textures  with probability of, 0.0\n['Unnatural noise or grain in', 'Uniform surfaces maintain clean smoothness', 'Textures or surfaces with natural']\nImage_9.png  processed for  Artificial noise patterns in uniform surfaces  with probability of, 0.8832287\n['Unwanted grainy patterns in complex', 'Surfaces are clean and free', 'Simple, smooth objects']\nImage_9.png  processed for  Random noise patterns in detailed areas  with probability of, 1.0\n['The same element appears multiple', 'Elements are unique and do', 'Natural or non-repetitive objects']\nImage_9.png  processed for  Repeated element patterns  with probability of, 1.0\n['Systematic color distribution anomalies occur', 'Colors are evenly distributed, with', 'Monochrome or simple color palettes']\nImage_9.png  processed for  Systematic color distribution anomalies  with probability of, 0.1246454\n['Colors shift abruptly or unnaturally', 'Colors shift naturally, with smooth', 'Flat, simple color fields']\nImage_9.png  processed for  Unnatural color transitions  with probability of, 0.292822\n['Colors in adjacent areas do', 'Colors transition smoothly between adjacent', 'Simple, uniform color scenes']\nImage_9.png  processed for  Color coherence breaks  with probability of, 0.9633377\n['Unnatural patterns in the frequency', 'The frequency spectrum of the', 'Simple, natural objects']\nImage_9.png  processed for  Frequency domain signatures  with probability of, 0.019855378\n['Overly polished areas that lack', 'Polished areas retain realistic texture', 'Rough or textured objects']\nImage_9.png  processed for  Artificial smoothness  with probability of, 0.9311988\n['Very detailed(overemphasized) features that look', 'Features are realistically detailed, avoiding', 'Realistic or minimally exaggerated models']\nImage_9.png  processed for  Exaggerated characteristic features  with probability of, 0.6517858\n['Materials look like they are', 'Materials exhibit realistic textures, avoiding', 'Natural or real-life materials']\nImage_9.png  processed for  Synthetic material appearance  with probability of, 0.17557769\n['Parts of an object appear', 'All components are properly connected', 'Well-grounded, stable structures']\nImage_9.png  processed for  Floating or disconnected components  with probability of, 0.73987776\n['Materials on the same object', 'Materials on the object accurately', 'Uniform, single-material objects']\nImage_9.png  processed for  Inconsistent material properties  with probability of, 0.17219272\n['Objects appear closer or farther', 'Objects are placed at realistic', '2D images or illustrations']\nImage_9.png  processed for  Depth perception anomalies  with probability of, 0.8103728\n['Important small details are missing.', 'Small details are present and', 'Simple objects or images with']\nImage_9.png  processed for  Loss of fine detail in complex structures  with probability of, 0.011014644\n['Different areas of an image', 'The image has uniform sharpness', 'Uniform resolution images']\nImage_9.png  processed for  Resolution inconsistencies within regions  with probability of, 0.020341562\n['Objects that end suddenly instead', 'Objects taper naturally, following proper', 'Fully rendered objects']\nImage_9.png  processed for  Abruptly cut off objects  with probability of, 0.0\n['Unnatural, harsh or very bright', 'Highlights are soft, natural, and', 'N/A for Matte or non-reflective']\nImage_9.png  processed for  Unrealistic specular highlights  with probability of, 0.0\n{'Image_1.png': ['Improper fur direction flows', 'Inconsistent object boundaries', 'Over-sharpening artifacts', 'Jagged edges in curved structures', 'Artificial depth of field in object presentation', 'Discontinuous surfaces', 'Unnaturally glossy surfaces', 'Metallic surface artifacts', 'Over-smoothing of natural textures', 'Random noise patterns in detailed areas', 'Artificial smoothness'], 'Image_6.png': ['Inconsistent object boundaries', 'Over-sharpening artifacts', 'Discontinuous surfaces', 'Unnaturally glossy surfaces', 'Metallic surface artifacts', 'Over-smoothing of natural textures', 'Color coherence breaks'], 'Image_3.png': ['Inconsistent object boundaries', 'Aliasing along high-contrast edges', 'Artificial noise patterns in uniform surfaces'], 'Image_2.png': ['Inconsistent object boundaries', 'Aliasing along high-contrast edges', 'Metallic surface artifacts', 'Color coherence breaks', 'Exaggerated characteristic features', 'Depth perception anomalies'], 'Image_5.png': ['Inconsistent object boundaries', 'Discontinuous surfaces', 'Unnaturally glossy surfaces', 'Metallic surface artifacts', 'Texture repetition patterns', 'Over-smoothing of natural textures', 'Random noise patterns in detailed areas', 'Color coherence breaks', 'Floating or disconnected components'], 'Image_7.png': ['Inconsistent object boundaries', 'Over-sharpening artifacts', 'Metallic surface artifacts', 'Over-smoothing of natural textures', 'Repeated element patterns'], 'Image_10.png': ['Improper fur direction flows', 'Inconsistent object boundaries', 'Over-sharpening artifacts', 'Excessive sharpness in certain image regions', 'Aliasing along high-contrast edges', 'Discontinuous surfaces', 'Metallic surface artifacts', 'Texture repetition patterns', 'Over-smoothing of natural textures', 'Random noise patterns in detailed areas', 'Repeated element patterns', 'Color coherence breaks', 'Artificial smoothness'], 'Image_8.png': ['Inconsistent object boundaries', 'Over-sharpening artifacts', 'Metallic surface artifacts', 'Texture repetition patterns', 'Repeated element patterns', 'Color coherence breaks', 'Floating or disconnected components', 'Depth perception anomalies'], 'Image_4.png': ['Inconsistent object boundaries', 'Discontinuous surfaces', 'Unnaturally glossy surfaces', 'Metallic surface artifacts'], 'Image_9.png': ['Inconsistent object boundaries', 'Metallic surface artifacts', 'Random noise patterns in detailed areas', 'Repeated element patterns', 'Color coherence breaks', 'Artificial smoothness']}\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"def concatenate_dicts(dict1, dict2):\n    # Ensure both dictionaries have the same keys\n    if set(dict1.keys()) != set(dict2.keys()):\n        raise ValueError(\"Dictionaries do not have the same keys.\")\n    \n    # Create the new dictionary with concatenated lists\n    concatenated_dict = {key: dict1[key] + dict2[key] for key in dict1.keys()}\n    return concatenated_dict\nresults = concatenate_dicts(result, result_32)\niou_scores = calculate_iou(image_artifacts, results)\nprint(iou_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:08.836217Z","iopub.execute_input":"2024-11-28T13:38:08.836569Z","iopub.status.idle":"2024-11-28T13:38:08.842604Z","shell.execute_reply.started":"2024-11-28T13:38:08.836537Z","shell.execute_reply":"2024-11-28T13:38:08.841633Z"}},"outputs":[{"name":"stdout","text":"{'Image_1.png': 0.09090909090909091, 'Image_2.png': 0.06666666666666667, 'Image_3.png': 0.0, 'Image_4.png': 0.16666666666666666, 'Image_5.png': 0.0, 'Image_6.png': 0.0, 'Image_7.png': 0.06666666666666667, 'Image_8.png': 0.047619047619047616, 'Image_9.png': 0.0}\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}