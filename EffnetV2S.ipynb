{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0zmAxAOXWRs",
        "outputId": "53db695b-7c75-4189-aae2-3599ad82fa61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped successfully. Files are extracted to: /content/final_datatset_split\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file\n",
        "zip_file_path = \"/content/perturbed_unperturbed_split.zip\"\n",
        "\n",
        "# Define the directory to extract files\n",
        "extract_to = \"/content/final_datatset_split\"\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Unzipped successfully. Files are extracted to:\", extract_to)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPw_a5CyvSxd",
        "outputId": "b7ff33d2-6efc-4893-9947-4e18f64437af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of files in the folder '/content/final_datatset_split' is: 221161\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to the folder\n",
        "folder_path = \"/content/final_datatset_split\"\n",
        "\n",
        "# Function to count files in a folder\n",
        "def count_files_in_folder(path):\n",
        "    file_count = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        file_count += len(filenames)\n",
        "    return file_count\n",
        "\n",
        "# Get the number of files\n",
        "total_files = count_files_in_folder(folder_path)\n",
        "\n",
        "print(f\"The total number of files in the folder '{folder_path}' is: {total_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxwB6-Onms_G",
        "outputId": "c9ceea63-37a0-4776-b03b-2de60a5ab029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of files in the ZIP file '/content/perturbed_unperturbed_split.zip' is: 221169\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_file_path = \"/content/perturbed_unperturbed_split.zip\"\n",
        "\n",
        "# Function to count files in a ZIP archive\n",
        "def count_files_in_zip(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_count = len(zip_ref.infolist())\n",
        "    return file_count\n",
        "\n",
        "# Get the number of files in the ZIP\n",
        "total_files_in_zip = count_files_in_zip(zip_file_path)\n",
        "\n",
        "print(f\"The total number of files in the ZIP file '{zip_file_path}' is: {total_files_in_zip}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7YsY5nn7s1iT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "from torchvision.transforms import transforms as T\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jcq5yef4s6P8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260ae05f-8d4f-4273-b295-7c91b10d1cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# New custom noise and filter classes\n",
        "class DoubleLayerGaussianFilter(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, sigma=1.0):\n",
        "        super(DoubleLayerGaussianFilter, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.sigma = sigma\n",
        "        self.gaussian_filter = self.create_gaussian_filter()\n",
        "\n",
        "    def create_gaussian_filter(self):\n",
        "        k = self.kernel_size // 2\n",
        "        x = torch.arange(-k, k + 1, dtype=torch.float32)\n",
        "        y = torch.arange(-k, k + 1, dtype=torch.float32)\n",
        "        xx, yy = torch.meshgrid(x, y)\n",
        "        kernel = torch.exp(-(xx**2 + yy**2) / (2 * self.sigma**2))\n",
        "        kernel /= kernel.sum()  # Normalize kernel\n",
        "        kernel = kernel.expand(self.channels, 1, -1, -1)\n",
        "        return nn.Parameter(kernel, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        padding = self.kernel_size // 2\n",
        "        x = nn.functional.conv2d(x, self.gaussian_filter, padding=padding, groups=self.channels)\n",
        "        x = nn.functional.conv2d(x, self.gaussian_filter, padding=padding, groups=self.channels)\n",
        "        return x\n",
        "\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "class ApplyDoubleGaussianFilter:\n",
        "    def __init__(self, kernel_size=3, sigma=1.0):\n",
        "        self.filter = DoubleLayerGaussianFilter(channels=5, kernel_size=kernel_size, sigma=sigma)\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        tensor = tensor.unsqueeze(0)  # Add batch dimension\n",
        "        filtered = self.filter(tensor)\n",
        "        return filtered.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "class AddCustomNoise:\n",
        "    def __init__(self, noise_level=0.1):\n",
        "        self.noise_level = noise_level\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        noise = torch.randn_like(tensor) * self.noise_level\n",
        "        return tensor + noise\n",
        "\n",
        "# Set device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define LBP preprocessing function\n",
        "def lbp_preprocessing(image):\n",
        "    image = resize(image, (32, 32), anti_aliasing=True)\n",
        "    if image.ndim == 2:\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "    elif image.shape[2] == 4:\n",
        "        image = image[:, :, :3]\n",
        "    image_rgb = image.astype(\"float32\")\n",
        "\n",
        "    image_gray = rgb2gray(image_rgb)\n",
        "    P, R = 8, 1\n",
        "    lbp = local_binary_pattern(image_gray, P, R, method=\"uniform\")\n",
        "    fft = np.log(np.abs(np.fft.fft2(image_gray)) + 1)\n",
        "\n",
        "    processed_image = np.transpose(\n",
        "        np.concatenate([\n",
        "            image_rgb,\n",
        "            np.expand_dims(lbp, axis=-1),\n",
        "            np.expand_dims(fft, axis=-1)\n",
        "        ], axis=-1),\n",
        "        (2, 0, 1)  # Channel-first format\n",
        "    )\n",
        "\n",
        "    return processed_image.astype(\"float32\")\n",
        "\n",
        "# Updated transform pipeline\n",
        "transform = T.Compose([\n",
        "    T.Resize(size=(32, 32)),\n",
        "    T.RandomApply([\n",
        "        T.RandomHorizontalFlip(p=0.3),\n",
        "        T.RandomVerticalFlip(p=0.3),\n",
        "        T.RandomAffine(degrees=0, scale=(0.8, 1.2)),\n",
        "    ], p=0.3),\n",
        "    T.RandomApply([\n",
        "        ApplyDoubleGaussianFilter(kernel_size=3, sigma=1.0),\n",
        "        AddCustomNoise(noise_level=0.1)\n",
        "    ], p=0.3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DjkjFTWws9fF"
      },
      "outputs": [],
      "source": [
        "# Custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None, preprocess_fn=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        img = imread(img_path)\n",
        "        img = self.preprocess_fn(img)\n",
        "        img = torch.from_numpy(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Prepare dataset paths and labels\n",
        "def prepare_dataset(base_dir):\n",
        "    # Check if the directory exists\n",
        "    if not os.path.isdir(base_dir):\n",
        "        raise ValueError(f\"Directory {base_dir} does not exist.\")\n",
        "\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Assuming all images in 'unperturbed' folder are to be labeled as 0 (for unperturbed)\n",
        "    label = 0\n",
        "\n",
        "    # Loop through files in the base directory (unperturbed folder)\n",
        "    for fname in os.listdir(base_dir):\n",
        "        file_path = os.path.join(base_dir, fname)\n",
        "        # Only add image files (based on extension)\n",
        "        if os.path.isfile(file_path) and fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
        "            file_paths.append(file_path)\n",
        "            labels.append(label)  # Label as 0 for unperturbed images\n",
        "\n",
        "    return file_paths, labels\n",
        "\n",
        "\n",
        "# Paths to new train directory (Update this to your dataset location on Google Colab)\n",
        "train_dir = \"/content/final_datatset_split/train_final/unperturbed\"\n",
        "\n",
        "# Prepare full dataset\n",
        "file_paths, labels = prepare_dataset(train_dir)\n",
        "\n",
        "# Perform an 80/20 train-test split\n",
        "train_size = int(0.8 * len(file_paths))\n",
        "val_size = len(file_paths) - train_size\n",
        "\n",
        "train_paths, val_paths = random_split(file_paths, [train_size, val_size])\n",
        "train_labels, val_labels = random_split(labels, [train_size, val_size])\n",
        "\n",
        "# Create datasets\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = CustomDataset(train_paths, train_labels, transform=transform, preprocess_fn=lbp_preprocessing)\n",
        "val_dataset = CustomDataset(val_paths, val_labels, transform=transform, preprocess_fn=lbp_preprocessing)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1J6YWswtAYD",
        "outputId": "0ebeee2b-3e4f-48b3-bef3-a153a9b63514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 204MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Custom EfficientNetV2S for binary classification\n",
        "class CustomEffNetV2S(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(CustomEffNetV2S, self).__init__()\n",
        "        self.effnet = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "\n",
        "        original_first_conv = self.effnet.features[0][0]\n",
        "        new_first_conv = nn.Conv2d(\n",
        "            in_channels=5,\n",
        "            out_channels=original_first_conv.out_channels,\n",
        "            kernel_size=original_first_conv.kernel_size,\n",
        "            stride=original_first_conv.stride,\n",
        "            padding=original_first_conv.padding,\n",
        "            bias=original_first_conv.bias\n",
        "        )\n",
        "        with torch.no_grad():\n",
        "            new_first_conv.weight[:, :3, :, :] = original_first_conv.weight\n",
        "            new_first_conv.weight[:, 3:, :, :] = torch.randn_like(new_first_conv.weight[:, 3:, :, :]) * 0.01\n",
        "\n",
        "        self.effnet.features[0][0] = new_first_conv\n",
        "        self.effnet.classifier[1] = nn.Linear(self.effnet.classifier[1].in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.effnet(x)\n",
        "\n",
        "# Initialize the model\n",
        "model = CustomEffNetV2S().to(DEVICE)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEj6225szOE",
        "outputId": "866670da-df6b-404d-9db9-3fbca88e9002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/1267 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/skimage/feature/texture.py:360: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
            "  warnings.warn(\n",
            "Training:   2%|▏         | 20/1267 [07:24<7:41:41, 22.21s/it]"
          ]
        }
      ],
      "source": [
        "# Early stopping class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = float(\"inf\")\n",
        "        self.counter = 0\n",
        "        self.stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "# Training and validation loops\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, correct = 0.0, 0\n",
        "\n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    accuracy = correct / len(dataloader.dataset)\n",
        "    return epoch_loss, accuracy\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss, correct = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
        "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    accuracy = correct / len(dataloader.dataset)\n",
        "    return epoch_loss, accuracy\n",
        "\n",
        "# Start training with early stopping\n",
        "early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
        "num_epochs = 20\n",
        "best_val_loss = float(\"inf\")\n",
        "save_path = '/content/final_model.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_accuracy = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "    val_loss, val_accuracy = validate_epoch(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "\n",
        "    if early_stopping.stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Model training complete. Best model saved at {save_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}